% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% LaTeX4EI Example for Cheat Sheets
%
% @encode: 	UTF-8, tabwidth = 4, newline = LF
% @author:	LaTeX4EI
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %


% ======================================================================
% Document Settings
% ======================================================================

% possible options: color/nocolor, english/german, threecolumn
% default: color, english
\documentclass[german]{latex4ei/latex4ei_sheet}

% set document information
\title{Analysis 2 Zusammenfassung}
\author{Philipp van Kempen}					% optional, delete if unchanged
\myemail{philipp.van-kempen@tum.de}			% optional, delete if unchanged
\usepackage{color}
\usepackage{bbm}
% DOCUMENT_BEGIN ===============================================================
\begin{document}

\maketitle	% requires ./img/Logo.pdf


\newcommand{\Lim}[1]{\raisebox{0.5ex}{\scalebox{0.8}{$\displaystyle \lim_{#1}\;$}}}

\section{Allgemeines}
\subsection*{Vorgehensweise}
\begin{itemize}
\item Bei Betr\"agen: Fallunterscheidungen um die Funktion in einer Umgebung zu vereinfachen, damit ein Teil der Betr\"age wegfällt.
\item Stetigkeit in einem Punkt kann nicht im Punkt allein untersucht werden $\Rightarrow$ Nutze Definition!
\item CSU: Das Skalarprodukt 2er Vektoren ist kleiner gleich dem Produkt der Betr\"age!
\item Pr\"ufe ob zwei partielle Ableitungen $\partial_x f, \partial y f$ zu einer gemeinsamen zweimal stetig differenzierbaren Funktion $f$ geh\"oren: Satz von Schwarz pr\"ufen!\\
\item $\sqrt[m]{a^n} = a^{\frac{n}{m}}$\\
\item $x^y=e^{y \cdot ln(x)}$\\
\item Zum zeigen von Identit\"aten berechnet man die linke Seite der Gleichung sowie die rechte Seite und vergleicht beides.
\item Herleitung von Laplace f\"ur Koordinatentransformation:\\
Verwende $\partial_z u=\partial_z \tilde{u}$ f\"ur $\partial_z^2 u=\partial_z \partial_z u =\partial_z \tilde{u}=\partial_z v$ mit $v=\partial_z \tilde{u}$, also: $\partial_z^2=\partial_z^2 \tilde{u}$
\item Menge, welche die $z$-Achse beschreibt: $\{\vect{x \\ y \\ z} | x=y=0\}$
\item $x^y=e^{x \log(y)}$
\item kritischer Punkt $\Leftrightarrow$ station\"arer Punkt $\Leftrightarrow f'(x)=0$
\item Finde orthogonalen Vektor $u$ zu $v$ in $\R^2$: Komponenten vertauschen und eine der beiden negieren!
\item Manchmal kann man Integrale \"uber gebrochene Polynome evereinfachern, indem man Nullstellen Berechnet und Faktorisiert, sodass man den Nenner k\"urzen kann.

\subsection{Aufgaben}
\begin{itemize}
\item Kurve, welche beliebige Geraden durch Ursprung beschreibt: $k(t)=t \cdot \vect{a \\b}, \vect{a\\b}\neq 0$
\end{itemize}

\end{itemize}
\subsection{Begriffe}
$B \Rightarrow A$: A ist notwendig f\"ur B. Ist A nicht erf\"ullt, so kann auch B nicht erf\"ullt sein!\\
$A \Rightarrow B$: A ist hinreichend f\"ur B. Aus A folgt B.


\subsection*{Analysis 1}
\begin{itemize}
\item CSU: Cauchy-Schwarze-Ungleichung: $a,b \in \R^n, (a^\top b)\le \|a\|\cdot \|b\| \Rightarrow$ Skalarprodukt zweier Vektoren ist immer kleiner gleich dem Produkt deren Betr\"age! 
\item Haupsatz der Differential- und Integralrechnung:
\begin{enumerate}
\item TODO
\item $\int_a^b f'(t) d t=f(b)-f(a)$
\end{enumerate}
\end{itemize}

\section{Mengen und Grenzwerte in $\mathbb{R}^n$}

\begin{sectionbox}
	\subsection*{Offene Kugel}
	Mittelpunkt $x_0 \in \mathbb{R}^n$\\
	Radius $r > 0$\\
	$\Omega=B_r(x_0)=\{x \in \mathbb{R}^n|\|x-x_0\|<r\}$\\
	
	\subsection*{Abgeschlossene Kugel}
	Mittelpunkt $x_0 \in \mathbb{R}^n$\\
	Radius $r > 0$\\
	$\Omega=K_r(x_0)=\{x \in \mathbb{R}^n|\|x-x_0\|\le r\}$\\
	
	\subsection*{Einheitskugel}
	$B_1(x_0)$ mit $|x_i|\le 1, x\in \Omega=B_1(x_0)$
\end{sectionbox}

\begin{sectionbox}
	\subsection*{Innerer Punkt}
	Ein Punkt $x \in \Omega \subset \mathbb{R}^n$ hei\ss{}t innerer Punkt von $\Omega$, falls es eine offene Kugel $B_{\epsilon}(x), \epsilon > 0$ gibt, die ganz in $\Omega$ liegt, d.h. $B_{\epsilon} \subset \Omega$. \\
	Grafisch: TODO
	
	\subsection*{Das Innere}
	Menge aller inneren Punkte von $\Omega$\\
	Bezeichung: $int(\Omega)$\\
	
	\subsection*{Randpunkt}
	$x \in \mathbb{R}^n$ ist Randpunkt vom $\Omega$ wenn jede offene Kugel $B_\epsilon(x)$ sowohl Punkte in $\Omega$ als auch Punkte, die nicht in $\Omega$ sind beinhaltet.\\
	
	\subsection*{Rand}
	Menge aller Randpunkte $= \partial \Omega$\\
	
	\subsection*{Abschluss}
	$\overline{\Omega} = \Omega \cup \partial \Omega$
\end{sectionbox}
\begin{sectionbox}
	\subsection*{Offene Menge}
	Alle Punkte in $\Omega$ sind innere Punkte.\\
	$\Omega=int(\Omega) \Leftrightarrow \Omega $ ist offen.\\
	
	\subsection*{Abgeschlossene Menge}
	Menge $\Omega \subset \mathbb{R}^n$ ist abgeschlossen, falls alle Randpunkte in $\Omega$ liegen.\\
	$\delta \Omega \in \Omega \Leftrightarrow \Omega = \overline{\Omega}$
	
	\subsection*{Beschr\"ankte Menge}
	Menge $\Omega \subset \mathbb{R}^n$ ist beschränkt, wenn es eine Konstante $M>0$ gibt, sodass:\\
	$\|x\| \le M     \forall x \in \Omega$\\
	
	\subsection{Konvexe Mengen}
	Menge $\Omega$ hei\ss{}t konvex, wenn $\forall x,y\ in \Omega$ gilt: $[x,y]\subset\Omega$. D.h. die Verbindungsstrecke zweier beliebiger Punkte aus $\Omega$ liegt ganz in $\Omega$!
	grafisch: TODO\\
\end{sectionbox}
	\begin{cookbox}{Wichtige Beispiele}
	\item eine offene Kugel ist offen
	\item eine abgeschlossene Kugel ist abgeschlossen
	\item $\Omega = \mathbb{R}^n$ ist sowohl offen als auch abgeschlossen
	\item $\Omega = (0,1]$ ist weder offen, noch abgeschlossen
	\item $\Omega = \{0,1,25\}$ ist nicht offen, aber abgeschlossen
	\item $\Omega = \mathbb{Q} \subset \mathbb{R}$ ist nicht offen und nicht abgeschlossem.
	\item $\Omega = \emptyset$ ist ???
\end{cookbox}
	
\begin{cookbox}{Regeln}
	\item $A \subset \mathbb{R}^n$ ist abgeschlossen $\Rightarrow \mathbb{R}^n \setminus A$ ist offen
	\item $A \subset \mathbb{R}^n$ ist offen $\Rightarrow \mathbb{R}^n \diagdown A$ ist abgeschlossen
	\item $A,B \subset \mathbb{R}^n$ ist abgeschlossen $\Rightarrow A \cup B, A \cap B$ ist abgeschlossen
	\item $A,B \subset \mathbb{R}^n$ ist offen $\Rightarrow A \cup B, A \cap B$ ist offen
	\item $X$ ist offen $\Leftrightarrow$ $\partial X \cap X = \emptyset$
	\item $\R^n \diagdown \overline{X}=int(\R^n \diagdown X)$
\end{cookbox}

Gegenbeispiele f\"ur Aussagen \"uber Mengen in $\R^2$ haben meist die Form $\{(x,y)\in\R^2 | X \}$ mit Ungleichung $X$ wie z. B. $x>0,x\ge0,0\le x < 1,...$

\begin{sectionbox}
	\subsection*{Folgen im $\mathbb{R}^n$}
	Analog zu Folgen in $\mathbb{R}$ oder $\mathbb{C}$: $(x^k) \subset \mathbb{R}^2$\\
	komponentenweise!\\
	\textbf{Grenzert:}\\
	Vektor $x \in \mathbb{R}^2$ ist Grenzert der Folge $(x^k)$, wenn $\Lim{k \to \infty} \|x^k -x\| = 0$ erfüllt ist bzw. $\Lim{k \to \infty} x^k = x$\\
	\textbf{Satz:} ist $A \subset \mathbb{R}^n$ abgeschlossen und konvergiere die Folge $\{x^k\} \subset A$ gegen $x \in \mathbb{R}^n$. Dann gilt: $x \in A$\\
	\textbf{Skalarfelder:} $f: \Omega \subset \mathbb{R}^n \rightarrow \mathbb{R}$ konvergiert für $x \to y$ gegen $a \in \mathbb{R}$, wenn f\"ur alle Folgen $\{x^k\} \subset \Omega \diagdown \{y\}$ mit $x^k \to y$ $\Lim{k \to \infty} f(x^k) = a $ gilt.
	\end{sectionbox}
% SECTION ====================================================================================
\section{Skalarfelder}
% ============================================================================================



\begin{sectionbox}

	\subsection{Definition}
	EIn Skalarfeld ist eine Funktion $f:\Omega \rightarrow \mathbb{R}$ wobei $\Omega \subset \mathbb{R}^n$ eine Teilmenge von $\mathbb{R}^n$ ist.
\end{sectionbox}
\begin{sectionbox}	
	\subsection{Stetigkeit}
	$f: \Omega \subset \mathbb{R}^n \rightarrow \mathbb{R}$\\
	Sei $f$ ein Skalarfeld und $y \in \Omega$.
	f ist stetig $\Leftrightarrow \Lim{x \to y} f(x) = f(y)$\\
	F\"uer jede Folge $\{x^k\} \in \Omega$ mit $x^k \rightarrow y$ die Folge der Funktionwerte $\{f(x^k)\}$ gegen $f(y)$ konvergieren muss. (In $\mathbb{R}$ existieren nur 2 Richtungen, in $\mathbb{R}^n$ dagegen unendlich viele Trajektoren!)
	\begin{cookbox}{Rechenregeln (wie in $\mathbb{R}$)}
	\item Differenz zweiter stetigen Funktionen ist wieder stetig
	\item Summe zweiter stetigen Funktionen ist wieder stetig
	\item Produkt zweier stetigen Funktionen ist wieder stetig
	\item Quotient zweiter stetiger Funktionen ist stetig, wenn Nenner $\neq 0$ 
	\item Stetige Funktionen: $f,g: \mathbb{R}^n \rightarrow \mathbb{R}, f(x)=a^Tx, g(x)=x^T A x mit a \in \mathbb{R}^n, A \in \mathbb{R}^{n \times n}$
	\item Unstetige Funktionen: TODO
\end{cookbox}
\textbf{Tipp:} Es reicht, eine Folge zu finden, f\"ur die der Grenzwert nicht mit dem Funktionswert \"ubereinstimmt, um Unstetigkeit zu beweisen!
\end{sectionbox}
\begin{sectionbox}	
	\subsection{Kompaktheit}
	Eine Menge $\Omega \subset \mathbb{R}^n$ hei\ss{}t kompakt, wenn jede Folge $\{x_k\} \subset \Omega$ eine konvergente Teilfolge $\{x_{k_l}\}$ besitzt, mit Grenzwert $\in \Omega$\\
	\textbf{Satz:} Eine Menge $\Omega \subset \mathbb{R}^n$ ist genau dann kompakt, wenn sie beschr\"ankt und abgeschlossen ist. (F\"ur endliches $\Omega$ gilt $\Leftrightarrow$)
	
	\subsection{Maximum und Minimum}
	Sei $\Omega \subset \mathbb{R}^n$ eine kompakte Menge und sei $f: \Omega \Rightarrow \mathbb{R}$ ein stetiges Skalarfeld. Dann nimmt $f$ auf $\Omega$ sein Minimum und sein Maximum an, d. h. $\exists x_m, x_M \in \Omega$ mit $f(x_m)=\min_{x \in \Omega} f(x)$ und $f(x_M)=\max_{x \in \Omega} f(x)$
\end{sectionbox}
\begin{sectionbox}	


	\subsection{partielle Funktionen}
	H\"alt man alle Variablen bis auf eine fest, kann man f\"ur ein Skalarfeld $f: \mathbb{R}^n \rightarrow \mathbb{R}$ partielle Funktionen an der Stelle $xQUERT \in \mathbb{R}^n$ betrachten.\\
	$\phi(x_1) = f(x_1, \overline{x}_2, ..., \overline{x}_n)$\\
	$\phi(x_2) = f(\overline{x}_1, x_2, ..., \overline{x}_n)$\\
	...\\
	Wir schr\"anken unsere Funktionen ein auf Geraden parallel zu den Achsen/auf den Achsen! Es ist m\"oglich, dass die partiellen Funktionen stetig sind, obwohl die Funktion unstetig ist!
	
	\subsection{partielle Ableitungen}
	$\Omega \subset \mathbb{R}^n$ offene Menge, $f:\Omega \rightarrow \mathbb{R}$, $\overline{x} \in \Omega$ gegeben.\\
	Ist die partielle Funktion $\phi_i(x_i)=f(\overline{x_1},...,x_i,...,\overline{x_n})$ differenzierbar, so nennt man ihre Ableitung partielle Ableitung. Die partielle Ableitung nach $x_i$ im Punkt $x$ wird definiert als\\
	$\frac{\partial f}{\partial_{x_i}}(x) = \Lim{h \to 0} \frac{f(x_1,...,x_{i-1},x_i+h,x_{i+1},...,x_n) - f(x_1,...,x_n)}{h}$\\
	Mit Verwendung von Einheitsvektoren:\\
	$\frac{\partial f}{\partial_{x_i}}(x) = \Lim{h \to 0} \frac{f(x+h e_i) - f(x)}{h} = \partial_{x_i}(x)=\partial_i f(x)$
	Zum Beispiel:\\
	$f(x)=a^T x=a_1 x_1+a_2 x_2,... \frac{\partial f}{\partial_{x_i}}(x)=a_i$
	$g(x)=x^T A x: \frac{\partial g}{\partial_{x_i}}(x)=e_i^T(A+A^T)x$ (bzw. falls symmetrisch: $2 e_i^T A x$)
\end{sectionbox}
\begin{sectionbox}	
	\subsection{Differenzierbarkeit}
	Funktion $f$ hei\ss{}t partiell differenzierbar, wenn alle partiellen Ableitungen (nach allex $x_i$) an der Stelle x existieren.\\
	Jede partielle Ableitung einer auf ganz $\Omega$ differenzierbaren Funktion definiert ein Skalarfeld.\\
	$f$ ist \textbf{stetig differenzierbar}, falls alle partiellen Ableitungen stetige Skalarfelder definieren.\\
	$\mathcal{C}^1(\Omega) = $ Menge aller einmal stetig differenzierbaren Skalarfelder

	
	\subsection{totale (Fr\'{e}chet) Differenzierbarkeit}
	Ein Skalarfeld $f$ hei\ss{}t total differenzierbar an der Stelle $x \in \Omega$, falls es einen Vektor $b \subset \mathbb{R}^n$ gibt, sodass die Darstellung $f(x+d)=f(x) + b^Td + o(\|d\|)$ f\"ur $d \in \mathbb{R}^n$ mit $||d|| \rightarrow 0$ gilt, also das Restglied geht schneller gegen Null als der Abstand $\| d \|$.\\
  $f$ total differenzierbar in Stelle x $\Rightarrow$ $f$ ist partiell diffbar an x und es gilt: $b=\nabla f(x)$ also $f(x+d)=f(x)+\nabla f(x)^T d + o(\|d\|)$\\
	Man kann also ein Fr\'echet diffbares Skalarfeld in einer Umgebung von x durch eine lineare Funktion approximieren\\
	TOTALES DIFFERENTIAL:\\
	\textbf{ $\mathbb{R}^1$:} differenzierbar $\Rightarrow$ stetig\\
	\textbf{ $\mathbb{R}^n$:} partiell differenzierbar $\nRightarrow$ stetig\\
  ABER: f Fr\'echet differenzierbar $\Rightarrow$ f stetig!\\
	Beweis: Angenommen f w\"are an Stelle x total differenzierbar,...\\
	$\Omega$ offen, f stetig differenzierbar $\Rightarrow$ f ist Frech\'et differenzierbar!\\
	Falls keine Aussage \"uber die Stetigkeit gemacht werden kann, kann man stattdessen nach Betechnung des Gradienten folgenden Grenzwert pr\"ufen: $\Lim{\|d\| \to 0} \frac{f(\overline{x}+dx,\overline{y}+dy)-f(\overline{x},\overline{y}) - \nabla f(\overline{x},\overline{y})^T d}{\|d\|}=0$\\
	\textbf{Beispiel:} $f(x,y)=|x y|$ ist total differenzierbar in den Punkten: TODO
	
	\begin{cookbox}{Rechenregeln f\"ur total differenzierbare Skalarfelder}
	\item $f+g$ total differenzierbar
	\item $f-g$ total differenzierbar
	\item $\alpha f$ total differenzierbar
	\item $\frac{f}{g}$ total differenzierbar falls $g(x) \neq 0$
\end{cookbox}

\end{sectionbox}
\begin{sectionbox}
	
	\subsection{Gradient}
	Der Gradient einer im partiell differenzierbaren Funktion im Punkt $x \in \Omega$ ist wie folgt definiert:\\
	$\nabla f(x) = 
	\begin{pmatrix}
		\frac{\partial f}{\partial_{x_1}} \\ ... \\ \frac{\partial f}{\partial_{x_n}}	
	\end{pmatrix}
	\in \mathbb{R}^n$ bzw. grad $ f(x) = \nabla f(x)$\\
	Der Gradient zeigt in die Richtung der st\"arksten Steigung bzw. $- \nabla f$ in die entgegengesetzte Richtung!\\
	Au\ss{}erdem steht der Gradient senkrecht auf H\"ohenlinien.\\
	\textbf{H\"ohenlinie:} TODO\\
	Zum Beispiel:\\
	$f(x)=a^T x: grad f(x)=
	\begin{pmatrix}
		a_1 \\ ... \\ a_n	
	\end{pmatrix}
	= a \in \mathbb{R}^n$\\
	$g(x)=x^T A x: \nabla g(x)=(A + A^T) x$ (bzw. falls symmetrisch $2 A x$)
	
	\begin{cookbox}{Rechenregeln f\"ur Gradienten}
	\item $\nabla (f+g)(x)=\nabla f(x) + \nabla g(x)$
	\item $\nabla (\lambda f)(x)=\lambda \nabla f(x)$
	\item $\nabla (f g)(x)=g(x) \nabla f(x) + f(x) \nabla g(x)$
	\item $\nabla (\frac{f}{g})(x)=\frac{1}{g(x)^2}(g(x) \lambda f(x) - f(x) \lambda g(x))$ falls Nenner $\neq 0$
	\item Kettenregel: Später!
	\item Polynome \& rationale Funktionen mit Nenner $\neq 0$ Fr\'echet differenzierbar!
\end{cookbox}
\end{sectionbox}
\begin{sectionbox}	
	\subsection{Richtungsableitung}
	Verallgemeinerung von partiellen Ableitungen!\\
	$\partial_d f(x) = \Lim{h \to 0} \frac{f(x+h d - f(x)}{h}$ mit $d \in \mathbb{R}^n$\\
	$\partial_{e_i} f(x)=\partial_{x_i} f(x)$\\
	$f$ total differenzierbar $\Rightarrow$ f\"ur jede Richtung $d \in \mathbb{R}^n$ die Richtungsanleitung und es gilt: $\partial_d f(x)=\nabla f(x)^T d$\\
  \textbf{Beispiele:}\\
	$f(x)=a^T x: \partial_d f(x)=a^T d$\\
	$g(x)=x^T A x: \partial_d g(x)=x^T (A+A^T) d$\\
	Wenn Formel $\partial_d f(x)=\nabla f(x)^T d$ nicht gilt, so ist f NICHT total differenzierbar!\\
	Verdoppelung der Länge des Richtungsvektor $2 \cdot \|d\|$ $\Rightarrow$ Verdoppelung der L\"ange des Gradienten!
	Betrag der Richtungsableitung gibt St\"arke der Steigung an.
\end{sectionbox}
\begin{sectionbox}	
	\subsection{Kettenregeln}
	\begin{enumerate}
	\item \textbf{Variante}\\
	$f:\Omega \in \mathbb{R}^n \rightarrow \mathbb{R}$ Fr\'echet differenzierbar, $g: \mathbb{R} \rightarrow \mathbb{R} $differenzierbar:\\
	Zusammensetzung $h(x)=(g \cdot \circ f)(x)=g(f(x))$ definiert ein Skalarfeld, welches total differenzierbar ist. $h: \Omega \rightarrow \mathbb{R}$\\
	Partielle Ableitung: $\frac{\partial h(x)}{\partial_{x_i}}=g'(f(x))\cdot \frac{\partial f(x)}{\partial_{x_i}}$ wie mit der Kettenregel\\
	Gradient: $\nabla h(x)=g'(f(x))\cdot \nabla f(x)$
	\item \textbf{Variante}
	$k:I=[a,b] \rightarrow \mathbb{R}^n$ differenzierbare Kurve, $f: \Omega \subset \mathbb{R}^n \rightarrow \mathbb{R}$ total differenzierbates Skalarfeld:\\
	Komposition: $g = f \circ k, g(t)=f(k(t))$ mit $g: [a,b] \rightarrow \mathbb{R}$ ist differenzierbar\\
	Ableitung: $g'(t)=\nabla f(k(t))^T \cdot k'(t)=TODOSUMME \frac{\partial f}{\partial_{x_i}} (k(t)) \cdot k_i'(t)$\\
	\textbf{Merke:}	Immer das gleiche!
	\end{enumerate}
\end{sectionbox}
\begin{sectionbox}		
	\subsection*{radialsymmetrische Skalarfelder}
	\textbf{Eigenschaft:} $\|x\| = \|y\| \Rightarrow f(x) = f(y) \Rightarrow$ Nur der Abstand zum Ursprung ist entscheident, nicht die Richtung!\\
	Man kann rad.-sym. Skalafelder schreiben als: $f(x)=g(r(x))$ mit $r(x)=\|x\|$ und $g: \mathbb{R} \rightarrow \mathbb{R}$\\
	Gradient: $\partial_{x_i} r(x)=\frac{x_i}{\|x\|} \Rightarrow \nabla f(x)=\frac{g'(\|x\|)}{\|x\|}x$ \\
\end{sectionbox}	
	
	\subsection{Höhere partielle Ableitungen}
	Die partiellen Ableitungen des Gradienten eines Skalarfeldes, welcher wieder ein Skalarfeld definiert heißen h\"ohere partielle Ableitungen\\
	$\Omega \subset \mathbb{R}^n$ offen, $f: \Omega \rightarrow \mathbb{R}$ partiell differenzierbar.\\
	Zweite Ableitung (falls existent): $\partial_{x_j} \partial_{x_i} f(x)=\frac{\partial^2}{\partial_{x_j x_i} } f(x) = \partial_j \partial_i f(x) = \partial_{x_j} (\partial_{x_i})= \Lim{h \to 0} \frac{1}{h} (\partial_{x_i}? f (x + h e_i)- \partial_{x_i}? f(x)) $\\
	$\partial_{x_i} \partial_{x_i} = \frac{\partial^2}{\partial_{x_i}^2} f(x)$\\
	$f$ zweimal stetig partiell differentierbar $\Leftrightarrow f \in \mathcal{C}^2(\Omega) \Leftrightarrow $ Alle zweiten partiellen Ableitungen existieren und sind stetig. (Analog: $\mathcal{C}^m$)\\
	\textbf{Satz von Schwarz:} $f: \Omega \rightarrow \mathbb{R}, f \in \mathcal{C}^2$ So gilt: $\partial_{x_i} \partial_{x_j} f(x) = \partial_{x_j} \partial_{x_i} f(x) \forall 1\le i,j \le n \forall x \in \Omega$\\
	Im Allgemeinen ($f NOT \in \mathcal{C}^2$) kann die Reihenfolge der Ableitungen entscheidend sein. Verallgemeinerung auf h\"ohere Stufen m\"oglich ($\partial_{x_1} \partial_{x_3} \partial_{x_7} f = \partial_{x_7} \partial_{x_1} \partial_{x_3} f$ usw).\\
	Die zweiten partiellen Ableitungen eines zweimal partiell differenzierbaren Skalarfeldes bilden die sogenannte \textbf{Hesse-Matrix}\\ $H_f (x) = \nabla^2 f(x) = \begin{pmatrix}
		\partial_{x_1} \partial_{x_1} f(x) & ... & \partial_{x_n} \partial_{x_1} f(x) \\ \partial_{x_1} \partial_{x_2} f(x) & ... & \partial_{x_n} \partial_{x_2} f(x) \\ \vdots \  \  \\ \partial_{x_1} \partial_{x_n} & ... & \partial_{x_n} \partial_{x_n} 	
	\end{pmatrix}$ 
	Es gilt: $f \in \mathcal{C}^2(\Omega) \Leftrightarrow H_f(x)$ ist symmetrisch ($H_f(x)^T = H_f(x))$\\
\textbf{Wichtige Beispiele:}\\
\begin{itemize}

\item $f(x)=a^T x, a \in \mathbb{R}^n \Rightarrow H_f (x) = 0 \in \mathbb{R}^{n \times n}$ \item $f(x)=x^T A x, A \in \mathbb{R}^{n \times n} \Rightarrow H_f (x) = A + A^T$
\item $f(x)=\|x\| \Rightarrow H_f (x) = \frac{1}{\|x\|} \cdot \mathbb{1}_n - \frac{1}{\|x\|^3} x x^T$

\end{itemize}

\subsection{Taylorentwicklung f\"ur Skalarfelder}
\textbf{Taylorpolynom:} $T_m (a ; a+h) = g(0) + g’(0) + \frac{1}{2!} g''(0) + ... + \frac{1}{m!} g_m(0)$ mit $g: [0,1] \rightarrow \mathbb{R}, g(t)=f(a+t h), g(0)=f(a)$ \\ $g’(0)=\nabla f(a)T \cdot h = SUMME TODO \partial_{x_i}f(a) h_i$\\
$T_3(a ; a+h)=f(a)+ \sum_{i=1}^{n} \partial_{x_i} f(a) h_i + \frac{1}{2} \sum_{i,j=1}^{n} \partial_{x_i} \partial_{x_j} f(a) h_i h_j + \frac{1}{6} \sum_{i,j,k=1}^{n} \partial_{x_i} \partial_{x_j} \partial_{x_k} f(a) h_i h_j h_k$ (Mit $x=a+h \Leftrightarrow h=x-a$) Schreibarbeit sparen: $h=\begin{pmatrix} x-x_0 \\ y-y_0\end{pmatrix}$ mit $a=\begin{pmatrix}x_0 \\ y_0\end{pmatrix}$ und nur f\"ur feste Zahlen einsetzen!\\\\
Alternativ: $T_3(a ; a+h)=f(a)+ \nabla f(a)^T h + h^T H_f(a) h + \frac{1}{6} \sum_{i,j,k=1}^{n} \partial_{x_i} \partial_{x_j} \partial_{x_k} f(a) h_i h_j h_k$

$g''(0)=\sum_{i,j=0}^n \partial_{x_i} \partial_{x_j} f(a) h_i h_j = h^T H_f(a) h$\\
$g'''(0)=\sum_{i,j,k}^n \partial _{x_i} \partial_{x_j} \partial_{x_k} f(a) h_i h_j h_k$(H\"ohere Ableitungen analog!)\\
\textbf{Restglieddarstellungen:}
\begin{itemize}
\item $R_{m+1}(a; a+h)=\frac{1}{m!} INTEGRAL (1-t)^m g^{(m+1)}(t) dt$
\item $R_{m+1}(a; a+h)=\frac{1}{m!}g^{(m+1)}(\psi)=\mathcal{O}(\|h\|^{m+1})$ mit $\psi \in (0;1)$ wenn $f \in \mathcal{C}^{m+1}(\Omega)$
\item $R_{m+1}(a; a+h)=o(\|h\|^{m})$ wenn $f \in \mathcal{C}^{m}(\Omega)$
\end{itemize}
\textbf{Spezialf\"alle:}
\begin{itemize}
\item $m=1: f \in \mathcal{C}^2(\Omega) f(a+h)=f(a)+\nabla f(a)^T h + \mathcal{O}(\|h\|^2)$ 
\item $m=2: f \in \mathcal{C}^3(\Omega) f(a+h)=f(a)+\nabla f(a)^T h + \frac{1}{2} h^T H_f(a) h + o(\|h\|^3)$
\end{itemize}


\section{Vektorfelder}
\subsection{Differenzierbarkeit, Jacobi-Matrix}
\subsubsection*{Definition}
Funktion $f:\Omega \subset \mathbb{R}^n \rightarrow \mathbb{R}^m$
\subsubsection*{Komponentenfunktionen}
Vektorfelder bestehen aus $m$ Skalarfeldern, die man Komponentenfunktionen $f_i:\Omega \rightarrow \mathbb{R}$ nennt.\\
\[x \in \Omega \subset \mathbb{R}^n \mapsto f(x) \in \mathbb{R}^m f(x)=\begin{pmatrix} f_1(x) \\ \vdots \\ f_m(x)\end{pmatrix} f_i: \Omega \rightarrow \mathbb{R}\]
Skalarfelder sind Spezialf\"alle von Vektorfeldern mit $m=1$\\

\subsubsection*{Grenzwerte}
komponentenweise!

\subsubsection*{Stetigkeit}
$f$ ist stetig an der Stelle $x_0 \in \Omega$, falls alle Komponentenfunktionen dort stetig sind

\subsubsection*{Partielle Differenzierbarkeit}
$f$ ist partiell differenzierbar an $x_0 \in \Omega$, falls alle Komponenten $f_i$ an dieser Stelle partiell differenzierbar sind. Das hei\ss{}t es existieren $\partial_j f_i(x_0), 1 \le i \le m, 1 \le j \le n$\\
$f$ ist stetig differenzierbar auf $\Omega \Leftrightarrow f \in \mathcal{C}^1(\Omega) \Leftrightarrow $ Alle $\partial_j f_i (x)$ sind stetig\\
\textbf{Jacobi-Matrix,Funktionalmatrix:} \[J_f(x) \in \mathbb{R}^{m \times n}=\begin{pmatrix} TODO \end{pmatrix}=\begin{pmatrix} \nabla f_1(x)^T \\ \vdots \\ \nabla f_m(x)^T \end{pmatrix} \]
Skalarfeld $g$: $J_g (x)=\nabla g(x)^T \in \mathbb{R}^{1 \times n}$\\
\textbf{Wichtige Beispiele:}
\begin{itemize}
\item $f: \mathbb{R}^n \rightarrow \mathbb{R}^m, f(x)=A x, A \in \mathbb{R}^{m\times n} \Rightarrow J_f(x)=A$
\item Skalarfeld $g: \mathbb{R}^n \rightarrow \mathbb{R}, g \in \mathcal{C}^2(\Omega) \Rightarrow$ Gradient $\nabla g$ definiert differenzierbates Vektorfeld! $\Rightarrow J_{\nabla g}(x)= H_g(x)$
\end{itemize}
\subsubsection*{Koordinatentransformationen}
\begin{itemize}
\item \textbf{lineare Koordinatentransformation/Basistransformation:}
$f: \mathbb{R}^n \rightarrow \mathbb{R}^n, f(x)= A x, A \in \mathbb{R}^{n \times n}$\\
$y = A x$ bzw. $x= A^{-1} y \Rightarrow J_f(x)=A$\\
\item \textbf{Polarkoordinatentransformation:}
$x=r cos(\phi) y=r sin(\phi)$\\
$f: [0,+\infty) \times [0,2 \pi) \rightarrow \mathbb{R}^2$\\
$f(r,\phi)=\begin{pmatrix} r cos(\phi) \\ r sin(\phi) \end{pmatrix} \Rightarrow J_f(r,\phi)=\begin{pmatrix} cos(\phi) & -r sin(\phi) \\ sin(\phi) & r cos(\phi) \end{pmatrix}$\\
\item \textbf{Zylinderkoprdinaten:}
$f:[0,+\infty) \times [0,2 \pi) \times \mathbb{R} \rightarrow \mathbb{r}^3$\\
$f(r,\phi,z)=\begin{pmatrix} r cos(\phi) \\ r sin(\phi) \\ z \end{pmatrix} \Rightarrow J_f(r,\phi,z)=\begin{pmatrix} cos(\phi)& -r sin(\phi) & 0\\ sin(\phi) & r cos(\phi) & 0\\ 0 & 0 & 1\end{pmatrix}$\\
\item \textbf{Kugelkoordinaten:}
$f: [0,+\infty) \times [0,\pi) \times [0,2 \pi) \rightarrow \mathbb{R}^3$\\
$f(r,\theta ,\phi)=\begin{pmatrix} r cos(\phi) sin(\theta) \\ r sin(\phi) sin(\theta) \\ r cos(\theta)\end{pmatrix} \Rightarrow J_f(r,\theta,\phi)=\begin{pmatrix} cos(\phi) sin(\theta) & r cos(\phi) cos(\theta) & -r sin(\phi) cos(\theta)\\ sin(\phi) sin(\theta) & r sin(\phi) cos(\theta) & r cos(\phi) sin(\theta)\\ cos(\theta) & r sin(\theta) & 0 \end{pmatrix}$\\

\end{itemize}

\textbf{Rechenregeln:} $f,g: \Omega \subset \mathbb{R}^n \rightarrow \mathbb{R}^m$ differenzierbar. $\alpha,\beta \in \mathbb{R} $
\begin{itemize}
\item Linearit\"at: $\alpha f + \beta g$ differenzierbar!\\
$J_{\alpha f + \beta g}(x)=\alpha J_f(x) + \beta J_g (x)$
\item Produktregel: $h: \Omega \subset \mathbb{R}^n\rightarrow \mathbb{R} h(x)=f(x)^Tg(x)=g(x)^Tf(x)$ differenzierbar. $J_h(x)=g(x)^TJ_f(x)+f(x)^TJ_g(x) \in \R^{1 \times n}$\\
$\nabla h(x)=J_f(x)^T g(x)+J_g(x)^T f(x) \in \R^{n}$
\end{itemize}

\subsubsection{Fr\'echet Differenzierbarkeit f\"r Vektorfelder}
$\Omega \subset \R^n$ offen, $f:\Omega \rightarrow \R^m$ ist Fr\'echet differenzierbar an $x\in \Omega$, falls eine lineare Abbildung $T:\R^n \rightarrow \R^m$ gibt, sodass: $f(x+h)=f(x)+T(h)+o(\|h\|)$ f\"ur $\|h\|\to 0$\\
F\"ur Skalarfelder ist $T$ die Abbildung mit dem Gradienten. Ist $f$ an $x$ total differenzierbar wird $T$ mithilfe der Jacobi-Matrix(bzgl. Standarbasis) definiert: $T(h)=J_f(x) h$ also: $f(x+h)=f(x)+J_f(x) h+o(\|o\|)$\\
Oft einfacher: Alle Komponentenfunktionen von $f$ sind Fr\'echet differenzierbar $\Leftrightarrow$ Vektorfeld $f$ Fr\'echet differenzierbar\\
Fr\'echet Ableitung: $D f(x): \R^n \rightarrow \R^m$ (x ist KEIN Argument der Funktion, es handelt sich nur um die Stelle x an der differenziert wird! D. h. $D f(x)(h)$ erwartet nur einen Vektor $h \in \R^n$)\\
$f: \R^n \rightarrow \R^m$ stetig diffbar, also $f \in \mathcal{C}^1(\Omega) \Rightarrow $ f ist Fr\'echet differenzierbar und die Ableitung wieder stetig.

\subsubsection{Verallgemeinerung der Kettenregel f\"ur Vektorfelder}
$\Omega \subset \R^n, D \subset \R^m$ offen, $f: \Omega \rightarrow \R^m, g: D \rightarrow \R^l$\\
Wenn $f$ in $x \in \Omega$ und $g$ in $y=f(x)\in D$ total differenzierbar ist, so ist die Komposition $h=g \circ f$ an $x$ wieder total differenzierbar mit:\\
$Dh(x)=D_g(f(x))=D_g(y) \circ Df(x) \Rightarrow$\\
$J_h(x)=J_g(f(x))\cdot J_f(x)$\\
F\"ur einen EIntrag der Jacobi-Matrix gilt:\\
$(J_h(x))_{ji}=\partial_i h_j(x)=\sum_{k=1}^{m} \partial_k g_i(f(x))\cdot \partial_j f_k(x)$\\
\textbf{Identit\"aten:}
\begin{itemize}
\item $f:\R^n \rightarrow \R, g:\R^n \rightarrow \R^m,h: \R^n \rightarrow \R^m, h(x) = f(x) g(x) \Rightarrow J_h(x) = g(x) J_f(x) + f(x) J_g(x)$
\item $f, g : \R^m \to \R^m,h : \R^n \rightarrow \R, h(x) = f(x)^T g(x) \Rightarrow J_h(x) = g(x)^T J_f (x) + f(x)^T J_g(x)$
\end{itemize}

\subsubsection*{\"Ubergang zu Polarkoordinaten mit der Kettenregel}
Skalarfeld: $u: \R^2 \rightarrow \R$ total differenzierbar\\
$f: [0,\infty) \times [0,2\pi) \rightarrow \R^2$\\
$f(r,\phi)=\begin{pmatrix}
r \cdot cos \phi \\ r \cdot sin \phi
\end{pmatrix} = \begin{pmatrix}
x \\ y
\end{pmatrix}$\\
$\tilde{u}=u \circ f=u(f(r,\phi))=u(r \cdot cos \phi, r \cot sin \phi)$\\
$f: [0,\infty) \times [0,2\pi) \rightarrow \R$\\
$J_{\tilde{u}}=\begin{pmatrix}
\partial_r \tilde{u} & \partial_\phi \tilde{u}
\end{pmatrix}$\\
$J_{u}=\begin{pmatrix}
\partial_x u & \partial_y u
\end{pmatrix}$\\
$J_{\tilde{u}} = J_u \cdot J_f$ mit $J_f=\begin{pmatrix}
cos \phi & -r \cdot sin \phi \\  sin \phi & r \cdot cos \phi
\end{pmatrix}$\\
$\Rightarrow \begin{pmatrix}
\partial_r \tilde{u} & \partial_\phi \tilde{u}
\end{pmatrix} = \begin{pmatrix}
\partial_x u & \partial_y u
\end{pmatrix} \cdot \begin{pmatrix}
s.o.
\end{pmatrix}$\\
$\begin{pmatrix}
\partial_r \tilde{u} & \partial_\phi \tilde{u}
\end{pmatrix}\\ = \begin{pmatrix}
\partial_x u \cdot cos \phi + \partial_y u \cdot sin \phi & - \partial_x u \cdot r \cdot sin \phi + \partial_y u \cdot r \cdot cos \phi
\end{pmatrix}$\\
Genauso l\"asst sich $\begin{pmatrix}
\partial_x u & \partial_y u
\end{pmatrix}$ mit $J_f^{-1}$ ausdr\"ucken!\\
Vorgehen:
\begin{enumerate}
\item Gegeben: $u(x,y)$
\item Berechne $\partial_x u, \partial_y u$
\item Setze $x=r \cdot cos \phi, y=r \cdot sin \phi$ ein in $u(x,y)$ ein um $\tilde{u}(r,\phi)$ zu erhalten
\item Berechne $\partial_r \tilde{u}, \partial_\phi \tilde{u}$ durch Ableiten von $\tilde{u}(r,\phi)$
\item Manchmal wird zwischen $u$ und $\tilde{u}$ nicht unterschieden: $u(r,\phi)=u(r \cdot cos \phi,r \cot sin \phi)$
\end{enumerate}
Kettenregel: $\frac{\partial u}{\partial r} = \frac{\partial u}{\partial x}\frac{\partial x}{\partial r} + \frac{\partial u}{\partial y}\frac{\partial y}{\partial r} $



\subsection{Laplace-Operator,Divergenz,Rotation (Differentialoperatoren)}
\textbf{BEACHTE:} Laplace usw. sind erstmal nur f\"ur kartesische Koordinaten ($x,y,z$) definiert. F\"ur Kugelkoordinaten usw. existieren Formeln!\\

\subsubsection{Lapace-Operator (Skalarfelder)}
\[f: \Omega \subset \R^n \rightarrow \R, f \in \mathcal{C}^2\]
\[\Delta f(x)=\sum_{i+1}^{n} \partial_i \partial_i f(x)\] (Summe der Diagonalelemente der Hesse-Matrix) \\
zweidimensionale Poissongleichung: $−\Delta u = 2$\\
eindimensionale W\"armeleitungsgleichung $\partial_t u - k\Delta u = 0$\\
dreidimensionale Wellengleichung $\partial_t^2 u − c^2\Delta u = 0$\\
Will man den Laplace-Operator auf ein Vektorfeld anweden, so geschieht dies komponentenweise!\\ 
Beachte: Der Laplace-Operator wird nur auf den Ort $x$ und niemals auf die Zeit $t$ angewendet!

\subsubsection{Divergenz (Vektorfelder)}
$F: \Omega \subset \R^{\textcolor{magenta}{n}} \rightarrow \R^{\textcolor{magenta}{n}}$ total differenzierbar (beachte $\textcolor{magenta}{n=m}$)\\
\[F(x)=\begin{pmatrix}
f_1(x)\\f_2(x)\\ \vdots \\ f_m(x)
\end{pmatrix}\]
\[\mathrm{div} F(x)=\sum_{i=1}^n \partial_i f_i (x)=\nabla \cdot F=\begin{pmatrix}
\partial_1 \\ \vdots \\ \partial_n
\end{pmatrix} \cdot \begin{pmatrix}
f_1 \\ \vdots \\ f_n
\end{pmatrix}\]
(Summe der Diagonalelemente der Jacobi-Matrix)

\subsubsection{Nabla-Operator}
Vektor aller partiellen Ableitungen:\\
$\nabla=\begin{pmatrix}
\partial_1 \\ \partial_2 \\ \vdots \\ \partial_n
\end{pmatrix}$

\subsubsection{Rotation}
Nur im $\R^3$! Englische Bezeichung: curl\\ 
$F:\Omega \subset \R^3 \rightarrow \R^3$ diffbar.\\
\[\mathrm{rot} F=\begin{pmatrix}
\partial_2 f_3 - \partial_3 f_2 \\ \partial_3 f_1 - \partial_1 f_3 \\ \partial_1 f_2 - \partial_2 f_1
\end{pmatrix}=\nabla \times F \in \R^3\mathrm{(Vektor)}\]

\subsubsection{Identit\"aten}
\begin{enumerate}
\item Skalarfeld $f: \Omega \in \R^n \rightarrow \R$ zwei mal stetig differenzierbar:\\
$\Delta f = div(\nabla f)= \nabla \cdot (\nabla f)$ mit (Skalarprodukt)
\item Skalarfeld $f: \Omega \in \R^n \rightarrow \R$ zwei mal stetig differenzierbar:\\
$\mathrm{rot}(\nabla f)=0$
\item Vektorfeld $F: \Omega \in \R^n \rightarrow \R^3$ zwei mal stetig differenzierbar:\\
$\mathrm{div}(\mathrm{rot} F)=0$ (Divergenzfrei)
\item $f (x, y, z) = (x, y, z)^T$\\
$\rot f=0, \nabla \|f\|=\frac{f}{\|f\|}, \div f=3$
\item Vektorfeld $u: \Omega \subset \R^3 \to \R \forall x \in \Omega$ und Vektoren $w \in \R^3$:\\
$(\rot u(x)) \times w = (J_u(x)-J_u(x)^\top)w$
\item Vektorfeld $v: \Omega \subset \R^3 \to \R^3$ zweimal stetig differenzierbar:\\
$\div(\rot v(x))=0$
\item Skalarfeld $u: \Omega \to \R$ stetig differenzierbar, Vektorfeld $v: \Omega \to \R^3$\\
$\div(u(x)v(x))=u(x)\div v(x)+v(x)^\top \nabla u(x)$\\
\item Skalarfeld $f: \Omega \subset \R^3 \to \R \forall x\ in \Omega$: zweimal stetig differenzierbar\\
$\rot(\nabla f(x))=0$
\item Vektorfeld $v: \Omega \subset \R^3 \to \R^3 \forall x\ in \Omega$:\\
$\rot(\rot v(x))=-\nabla v(x) + \nabla(\div v(x))$
\end{enumerate}

\subsection{Krummlinige Koordinaten}
\textbf{Beachte:} Bei Verwendung von Formeln aus den Netz er die Definition der Transformation z. B. anhand der Intervalle vergleichen.\\
Hinweise auf Kugelkoordinaten sind zum Beispiel $x^2+y^2+z^2$
\subsubsection{Koordinatentransformation}
Stetig differenzierbare Abbildung(Vektorfeld) $F:\Omega \subset \R^n \to \R^n$ (gleiche Dimension)

\subsubsection{Koordinatenvektor}
Koordinatenvektor in kartesischen Koordinaten: $x \in \R^n$\\
koordinatenvektor in neuen Koordinaten: $u \in \Omega \subset \R^n$\\
$x=F(u)$

\subsubsection{Koordinatenlinie}
Linie, die parallel zu einer der Koordinatenachsen durch den Punkt $x_0\in \R^n$ verl\"auft\\
$g_i=\{x\in\R^m|x_j=(x_0)_j \forall i\neq j, x_i \in \R\}$ bzw.\\
$g_i=\{x\in \R^n | x=x_0+t e_i, t \in \R \}$\\
Im Allgemeinen sind diese Linien bei neuen Koordinaten keine Geraden mehr: krummlinige Koordinaten!\\

\subsubsection{Koordinatenlinie bzgl. neuen Koordinaten}
$g_i=\{x=F(u) \in \R^n | u \in \Omega, u_j=(u_0)_j, j\neq i, u_i\in \R\}$\\
$g_i=\{x=F(u) \in \R^n | u \in \Omega, u=u_0+t e_i, t \in \R\}$
Beispiel: Polarkoordinaten: $g_21:$ $\phi_0$ fest, Winkel unver\"andert. Halbgerade von ursprung durch $x_0$; $g_2:$ Radius $r$ unver\"andert, Kreislinie durch $x_0$
\\


Schr\"ankt man die freie Variable $t$ auf ein Intervall $t\in [-\epsilon,\epsilon]$ ein, so wird durch die Koordinatenlinie eine Kurve durch $x_0$ definiert: $k_i(t)=F(u_0+t e_i)$ mit $k_i(0)=F(u_0)=x_0$

\subsubsection{Basis}
Um eine Basis im Punkt $x_0 = F(u_0)$ bzgl. krummliniger Koordinaten zu defnieren, betrachtet man Tangentialvektoren zu den Koordinatenlinien bzw. zu den Kurven $k_i$. Bekanntlich ist $k_i'(0)\in \R^n$ ein tangentialvektor zu der Kurve $k_i$ an der Stelle $x_0$.\\
$k_i(t)=F(u_0+t e_i)$\\
$k_i'(t)=J_F(u_0+t e_i)e_i$\\
$k_i'(0)=J_F(u_0)e_i$\\
Somit ist der $i$-te Spaltenvektor der Jacobi-Matrix ein Tangentialvektor zu der $i$-ten Koordinatenlinie an der Stelle $x_0=F(u_0)$.\\
Koordinatenvektoren m\"ussen linear unabh\"angig sein (also $J_F(u_0)$ regul\"ar $\Leftrightarrow \det J_F(u_0)\neq 0$), damit sie eine Basis bilden k\"onnen.

\subsubsection{Regu\"arer Punkt}
$x_0$ hei\ss{}t regul\"ar bzgl. einer Koordinatentransformation, wenn $\det J_f(u_0) \neq 0$. In seiner Umgebung ist die Transformation bijektiv, aso umkehrbar!\\

\subsubsection{lokale Basis}
Ist $x_0$ ein regul\"arer Punkt, so bilden die Spalten der Jacobi-Matrix eine Basis (lokale Basis im Punkt $x_0$).\\
$J_F(u_0)=\begin{pmatrix}
c_1 & c_2 & ... & c_n
\end{pmatrix}$\\
Die L\"angen dieser Vektoren hei\ss{}en \textbf{Ma\ss{}faktoren}: $h_i=\|c_i\|$
Normiert man diese Basis, so erh\"alt man eine normierte lokable Basis im Punkt $x_0$ (d.h. $\|\e_{u_i}|=1$)\\
$e_{u_1}=\frac{1}{h_1}c_1, e_{u_2}=\frac{1}{h_2}c_2,..., e_{u_n}=\frac{1}{h_n}c_n$

\subsubsection{Orthonormalbasis}
Wenn die Spalten der Matrix $J_f(u_0)$ orthogonal zueinander stehen, so bilden die normierten Vektoren eine Orthonormalbasis (ONB).\\
Transformationsmatrix $B=\begin{pmatrix}
e_{u_1} & ... & e_{u_n}
\end{pmatrix} $ ist dann orthogonal, also: $B^{-1}=B^T, B6T B=\mathbbm{1}_n$\\
Man spricht von \textbf{orthogonalen Koordinaten}.\\

In einem kartesischen Koordinatensystem h\"angt die Basis NICHT vom aktuellen Punkt ab. Bei krummlinigen Koordinatensystemen sind Basisvektoren $c_i=c_i(u)$ bzw. die normierten Basisvektoren $e_{u_i}=e_{u_i}(u)$ ortsabh\"angig!

\subsubsection{Beispiele}
\begin{itemize}
\item Polarkoordinaten: $J_F$ ist f\"ur $r\neq 0$ regul\"ar ($\det J_F(r,\phi)=r$), die Spalten sind orthogonal zueinander ($c_1^T c_2=0$), Ma\ss{}faktoren: $h_1=1, h_2=r$\\
lokale Basis  abh. von $\phi$: $e_r=\begin{pmatrix}
\cos \phi \\ \sin \phi
\end{pmatrix}, e_\phi=\begin{pmatrix}
-\sin \phi \\ \cos \phi
\end{pmatrix}$
\item Zylinderkoordinaten: $J_F$ ist f\"ur $r\neq 0$ regul\"ar ($\det J_F(r,\phi)=r$), die Spalten sind orthogonal zueinander, Ma\ss{}faktoren: $h_1=1, h_2=r, h_3=1$\\
lokale Basis: $e_r=\begin{pmatrix}
\cos \phi \\ \sin \phi \\0
\end{pmatrix}, e_\phi=\begin{pmatrix}
-\sin \phi \\ \cos \phi \\ 0
\end{pmatrix}, e_z=\begin{pmatrix}
0  \\ 0 \\ 1
\end{pmatrix}$
\item Kugelkoordinaten: $\det J_f(t,\theta,\phi)=r^2 \sin \theta$ f\"ur $r\neq 0$ und $0 < \theta < \pi$ ist Matrix regul\"ar und die Spalten sind othogonal! Ma\ss{}faktoren: $h_1=1, h_2=r, h_3=r \sin \theta$\\
lokale Basis:\\ $e_r=\begin{pmatrix}
\cos \phi \sin \theta \\ \sin \phi \sin \theta \\ \cos \theta
\end{pmatrix}, e_\theta=\begin{pmatrix}
\cos \phi \cos \theta \\ \sin \phi \cos \theta \\ -\sin \theta
\end{pmatrix},$\\
$e_\phi=\begin{pmatrix}
-\sin \phi \\ \cos \phi \\ 0
\end{pmatrix}$
\item Jacobi-Tranformation: F\"ur Bereichsintegrale! Grafisch zeichnen! Bildet von Einheitsquadrat auf Einheitsdreieck ab!\\
$T: \R^2 \to \R^2, T(u,v)=\vect{u (1-v) \\ u v}$\\
$J_T(u,v)=\mat{1-v & -v \\ v & u}, |\det J_T(u,v)|=|u| \neq 0$ bis auf Nullmengen!\\
\end{itemize}

\subsubsection{Gradient in krummlinigen Koordinaten}
$g: \R^n \to \R$ Skalarfeld, $F: \Omega \subset \R^n \to \R^m$ Koordinatentransformation\\
Skalarfeld bzgl. der neuen Koordinaten: Verkettung!\\
$\tilde{g}=g \circ F$, $\tilde{g}(u)=g(F(u))$ mit $F(u)=x$\\
Kettenregel: $G_{\tilde{g}}(u)=J_{g}(F(u)) \cdot J_F(u)$\\
Da $g$ Skalarfeld: $\nabla g(x)=(J_g)^T, \nabla \tilde{g}(x)=(J_{\tilde{g}}(x))^T$\\
$\Rightarrow \nabla g(x)=(J_F(u)^T)^{-1}\nabla \tilde{g}(u)$ mit $x=F(u)$\\
F\"ur orthogonale Koordinaten:\\
$J_F(u)=B H$ mit $B$ orthogonal bestehen aus normierten Basisvektoren $B=\begin{pmatrix}
e_{u_1} & ... & e_{u_n}
\end{pmatrix}$ und Diagonalmatrix $h=\begin{pmatrix}
h_1 & 0 & ... & 0 \\
0 & h_2 & ... & 0 \\
\vdots & \ddots & \ddots & \vdots \\
0 & 0 & ... & h_n 
\end{pmatrix} $ mit Ma\ss{}faktoren $h_i$\\
Vereinfacht: $\nabla g(x)=B H^{-1}\nabla \tilde{g}(u)$, $x=F(u)$\\
\textbf{Explizit:}\\
$\nabla g(x)=\frac{1}{h_1}\partial_{u_1} \tilde{g}(u) e_{u_1}+...+\frac{1}{h_n}\partial_{u_n} \tilde{g}(u) e_{u_n}$\\
\textbf{Polarkoordinaten:}\\
$\nabla g(x)=\partial_r \tilde{g}(r,\phi)e_r+\frac{1}{r} \partial \tilde{g}(r,\phi) e_\phi$\\
\textbf{Zylinderkoordinaten:}\\
$\nabla g(x)=\partial_r \tilde{g}(r,\phi,z)e_r+\frac{1}{r} \partial \tilde{g}(r,\phi,z) e_\phi+\partial_z \tilde{g}(r,\phi,z)e_z$\\
\textbf{Kugelkoordinaten:}\\
$\nabla g(x)=\partial_r \tilde{g}(r,\theta,\phi) e_r + \frac{1}{r} \partial_\theta \tilde{g}(r,\theta,\phi)e_\theta+\frac{1}{r \sin \theta} \partial_\phi \tilde{g}(r,\theta,\phi) e_\phi$\\

\textbf{Anmerkung:} F\"ur Ausdr\"ucke, welche skalare Gr\"o\ss{}en ergeben (Laplace,Divergenz), ist ist egal, ob man erst die Transformation durchf\"urt und dann den Operator anwendet oder erst den Oparator anwendet und dann die Koordinaten wechselt! Allerdings gilt dies nicht, wenn man mit vektorwertigen Ausdr\"ucken (Gradient, Rotation) zu tun hat, kommt beim anderen Weg nicht dasselbe raus, da man hier im Nachinein noch den Bildraum transformieren muss! (Siehe Vektorfelder!)

\subsection{Koordinatentranformationen f\"ur Vektorfelder}
Transformation sowohl im Urbild, als auch im Bildraum!\\
Koordinatentransformation $F: \Omega \subset \R^n \to \R^n$, Vektorfeld $G: \R^n \to \R^n, g(x)=g_1(x)e_1+...g_n(x)e_n$\\
Man erh\"alt Vektorfeld $\tilde{G}=G \circ F, \tilde{G}(u)=G(F(u))$ mit der Darstellung in der Standardbasis:
$\tilde{G}(u)\tilde{g}_1(u)e_1+...+\tilde{g}_n(u)e_n$ $\rightarrow$ Problematisch, da abh\"angig von kartesischen Koordinaten $e_1,...,e_n$!\\
Darstellung des vektorfeld bez\"uglich neuer lokaler Basis $e_{u_1},...,e_{u_n}$: $\hat{G}(u)=\vect{\hat{g}_1(u) \\ \vdots \\ \hat{g}_n(u)}$ sodass:\\
$G(x)=g_1(x)e_n+...+g_n(x)e_n=\tilde{g}_1(u)e_1+...+\tilde{g}_n(u)e_n=\hat{g}_1(u)e_{u_1}+...+\hat{g}_n(u)e_{u_n}$\\
Mit $B=\mat{e_{u_1} & ... & e_{u_n}}$ erh\"alt man wichtige Formeln:\\
allg.: $\hat{G}(u)=B^{-1}\tilde{G}(u)=B^{-1}G(x)$ mit $x=F(u)$\\
orthogonal: $\hat{G}(u)=B^\top \tilde{G}(u)=B^\top G(x)$ mit $x=F(u)$\\
\textbf{Transformation im Bildraum} notwendig, wenn man nicht in eine reele Zahl Abbildet, sondern in einen Vektor (Gradient, Rotation und Vektorfeld):\\
Entweder by-inspection mit etwas G\"uck ablesen, Sonst: $\hat{V}=S^\top \tilde{v}$\\
Bildet man in eine Zahl ab, so l\"asst sich $1:1$ umrechen!\\
Der Nullvektor ist in allen unseren bekannten Koordinaten der Nullvektor!\\

\subsection{Orthogonale Koordinatensysteme}
\subsubsection{Kartesische Koordinaten}
$F(r,\phi)=\vect{r \cos \phi \\ r \sin \phi}$\\
Skalarfeld $f$\\
Vektorfeld $g=\vect{g_1\\g_2\\g_3}$ bzgl. $e_x,e_y,e_z$\\
invers: TODO\\
$J_f(r,\phi)=$\\
$e_x=\vect{1\\0\\0},e_y=\vect{0\\1\\0},e_z=\vect{0\\0\\1}$\\
$\div g=\frac{\partial g_1}{\partial x}+ \frac{\partial g_2}{\partial y}+\frac{\partial g_3}{\partial z}$\\
$\Delta  f=\frac{\partial^2 f}{\partial x^2}+\frac{\partial^2 f}{\partial y^2}+\frac{\partial^2 f}{\partial z^2}$\\
$\nabla f=\vect{\frac{\partial f}{\partial x	}\\\frac{\partial f}{\partial y}\\\frac{\partial f}{\partial z	}}$ bzgl. $e_x,e_y,e_z$\\
$\rot F=\vect{\frac{\partial g_3}{\partial y} - \frac{\partial g_2}{\partial z}\\\frac{\partial g_1}{\partial z} - \frac{\partial g_3}{\partial x}\\\frac{\partial g_2}{\partial x} - \frac{\partial g_1}{\partial y}}$ bzgl. $e_x,e_y,e_z$\\

\subsubsection{Polarkoordinaten}
$F(r,\phi)=\vect{r \cos \phi \\ r \sin \phi}$\\

invers: TODO\\
$J_f(r,\phi)=\mat{\cos \phi & - r \sin \phi \\ \sin \phi & r \cos \phi}$\\
$e_r=\vect{cos \phi \\ \sin \phi}, e_\phi=\vect{\sin \phi \\ \cos \phi}$\\
$S=\mat{e_r & e_\phi}=\mat{\cos \phi & - \sin \phi \\ \sin \phi & \cos \phi}$\\

\subsubsection{Zylinderkoordinaten}
$F(r,\phi,z)=\vect{r \cos \phi \\ r \sin \phi \\ z}$\\
Skalarfeld $\utilde{f}$\\
Vektorfeld $\hat{g}=\vect{\hat{g}_1\\\hat{g}_2\\\hat{g}_3}$ bzgl. $e_r,e_\phi,e_z$
invers: TODO!\\
$e_r=\vect{\cos \phi \\ \sin \phi \\ 0}$, $e_\phi=\vect{-\sin \phi \\ \cos \phi \\ 0}$, $e_z=\vect{0 \\ 0 \\ 1}$ mit $\|e_r\|=\|e_\phi\|=\|e_z\|=1$\\
$S=\mat{e_r & e_\phi & e_z} = \mat{ \cos \phi & -\sin \phi & 0 \\ \sin \phi & \cos \phi & 0 \\ 0 & 0 & 1}$\\
$\tilde{\div F}=\frac{1}{r}\frac{\partial \hat{g}_1}{\partial r}+ \frac{1}{r}\frac{\partial \hat{g}_2}{\partial \phi}+\frac{\partial \hat{g}_3}{\partial z}$ \\
$\tilde{\Delta f}=\frac{\partial^2 \tilde{f}}{\partial r^2}+\frac{\partial^2 \tilde{f}}{\partial \phi^2}+\frac{\partial^2 \tilde{f}}{\partial z^2}$ \\
$\hat{\nabla f}=\vect{\frac{\partial \tilde{f}}{\partial r	}\\\frac{1}{r}\frac{\partial \tilde{f}}{\partial \phi}\\\frac{\partial \tilde{f}}{\partial z}}$ bzgl. $e_r,e_\phi,e_z$\\
$\hat{\rot F}=\vect{\frac{1}{r}\frac{\partial \hat{g}_3}{\partial \phi} - \frac{\partial \hat{g}_2}{\partial z}\\\frac{\partial \hat{g}_1}{\partial z} - \frac{\partial \hat{g}_3}{\partial r}\\\frac{1}{r}\frac{\partial (r \hat{g}_2)}{\partial r} - \frac{1}{r}\frac{\partial \hat{g}_1}{\partial \phi}}$ bzgl. $e_r,e_\phi,e_z$\\


\subsection{Kugelkoordinaten}
$F(r,\theta,\phi)=\vect{r \cos \phi \sin \theta\\ r \sin \phi \sin \theta\\ r \cos \theta}$\\
Skalarfeld $\utilde{f}$\\
Vektorfeld $\hat{g}=\vect{\hat{g}_1\\\hat{g}_2\\\hat{g}_3}$ bzgl. $e_r,e_\theta,e_\phi$
invers: TODO!\\
$J_f=\mat{\cos \phi \sin \theta & r \cos \phi \cos \theta & -r \sin \phi \sin \theta  \\
\sin\phi\sin\theta & r \sin \phi \cos \theta & r \cos \phi \sin \theta \\ \cos \theta & - r \sin \theta & 0}$\\
$e_r=\vect{\cos \phi \sin \theta \\ \sin \phi \sin \theta\\ \cos \theta}$, $e_\theta=\vect{\cos \phi \cos \theta \\ \sin \phi \cos \theta \\ \sin \theta}$, $e_\phi=\vect{\sin \phi \sin \theta \\ \cos \phi \sin \theta \\ 0}$ mit $\|e_r\|=\|e_\phi\|=\|e_z\|=1$\\
$S=\mat{\cos \phi \sin \theta &  \cos \phi \cos \theta & - \sin \phi \sin \theta  \\
\sin\phi\sin\theta &  \sin \phi \cos \theta &  \cos \phi \sin \theta \\ \cos \theta & -  \sin \theta & 0}$\\
$\tilde{\div F}=\frac{1}{r^2}\frac{\partial (r^2 \hat{g}_1)}{\partial r}+ \frac{1}{r sin \theta}\frac{\partial (\hat{g}_2 \sin \theta)}{\partial \theta}+\frac{1}{r \sin \theta}\frac{\partial \hat{g}_3}{\partial \phi}$ \\
$\tilde{\Delta f}=\frac{\partial^2 \tilde{f}}{\partial r^2}+TODOO HKFUGU\frac{\partial^2 \tilde{f}}{\partial \theta^2}+\frac{1}{r^2 \sin^2 \theta}\frac{\partial^2 \tilde{f}}{\partial \phi^2}$ \\
$\hat{\nabla f}=\vect{\frac{\partial \tilde{f}}{\partial r	}TODO\\\frac{1}{r}\frac{\partial \tilde{f}}{\partial \phi}\\\frac{\partial \tilde{f}}{\partial z}}$ bzgl. $e_r,e_\phi,e_z$\\
$\hat{\rot F}=\vect{\frac{1}{r}\frac{\partial \hat{g}_3}{\partial \phi}TODO - \frac{\partial \hat{g}_2}{\partial z}\\\frac{\partial \hat{g}_1}{\partial z} - \frac{\partial \hat{g}_3}{\partial r}\\\frac{1}{r}\frac{\partial (r \hat{g}_2)}{\partial r} - \frac{1}{r}\frac{\partial \hat{g}_1}{\partial \phi}}$ bzgl. $e_r,e_\phi,e_z$\\

\subsection{Implizite Funktionen}
Meistens sind Funktionen explizit gegeben durch $y=g(x)$. Desweiteren besteht die M\"oglichkeit einer impliziten Beschreibung, gegeben durch $f(x,y)=0$. Mit der Eigenschaft $f(x,g(x))=0$ ist die Funktion $y=g(x)$ eindeutig definiert. Manchmal ist eine Darstellung als explizite Funktion durch aufl\"osen nach $x$ oder $y$ m\"oglich!\\
Beispiele:\\
\begin{itemize}
\item $f(x,y)=2x+3y+3 \rightarrow y=-\frac{2}{3}x-1$
\item $f(x,y)=e^y+y^3-x^2-x^3-1 \rightarrow e^y+y^3=x^2+x^3+1$ was eindeutig ist, da $h(y)=e^y+y^3$ eindeutig ist!
\item Kreislinie $f(x,y)=x^2+y^2-r^2 \rightarrow$ 2 Funktionen: $g_1,g_2$ mit $y=\pm \sqrt{r^2-x^2}$\\
\end{itemize}
OHNE die Funktion $g(x)$ zu kennen kann man
falls die Ableitung einer impliziten Funktion existiert:\\
$0=f(x,g(x)) \rightarrow^{d x} 0=\partial_x f(x,g(x))+\partial_y f(x,g(x)) \cdot g'(x)$\\
Falls $\partial_y f(x,g(x))\neq 0: g'(x)=-\frac{\partial_x f(x,g(x))}{\partial_y f(x,g(x))}$\\ 
\textbf{Satz:} $D \subset \R^2, f: D \to \R$ stetig differenzierbar, Punkt $(x_0,y_0) \in D$ gegeben sodass: $f(x_0,y_0)=0$ erf\"ullt, aber $\partial_y f(x_0,y_0)\neq 0$, dann existieren zwei offene Intervalle $I \subset \R$ mit Mittelpunkt $x_0$ und $K \subset \R$ mit Mittelpunkt $y_0$ so dass:\\
\begin{itemize}
\item $R=I \times K \subset D$ und $\partial_y f(x,y)\neq 0 \forall (x,y) \in \R$
\item Durch $f(x,y)=0$ ist auf $I$ eindeutig eine differenzierbare Funktion $g:I \to K$ implizit definiert mit $y_0=g(x_0)$ und $f(x,g(x))=0 \forall x \in I$ und der Ableitung von g: $g'(x)=-\frac{\partial_x f(x,g(x))}{\partial_y f(x,g(x))}$
\end{itemize}
$\Rightarrow$ So ist falls die oben genennten Bedingungen erf\"ullt sind die Funktion in einer Umgebung nach $x$ bzw. nach $y$ aufl\"osbar!\\
Wenn $f \in \mathcal{C}^2(D)$ und die Vorraussetzungen erf\"ullt, so ist $g$ auch zweimal stetig differenzierbar. Zweite Ableitung: $g''=-\frac{1}{\partial_y f(x,g(x))}(\partial_x \partial_x f(x,g(x))+2 \partial_x \partial_y f(x,g(x))\cdot g'(x)+\partial_y \partial_y f(x,g(x))\cdot g'(x)^2)$\\
Was bring es einem die Ableitungen zu wissen, ohne das $g(x)$ zu kennen?: Manchmal sieht man Eigenschaften, wie zum Beispiel, dass einer Funktion f\"ur bestimmte $x$ eine positive Steigung besitzt usw.\\
Bei der Kreisline des Einheitskreises gilt $\partial_y f(x,y)=2y$ also gilt $\partial_y f(x,g(x))\neq 0 \Leftrightarrow g(x) \neq 0$, so ist die Funktion \"uberall, ausser an den 2 Punkten auf der x-Achse eindeutig durch zwei Funktionen $g_1,g_2$ f\"ur $y_0>0$ bzw. $y_0 < 0$ explizit angegeben. In einer Umgebung um $y_0=0$ kann man keine Funktion eindeutig definieren, da zu jedem Wert von $x$ zwei verschiedene $y$-Werte korrespondieren!

\begin{emphbox}
Wenn:
\begin{itemize}
\item $f$ stetig differenzierbar
\item $f(x_0,y_0)=0$
\item $\partial_y f(x_0,y_0)\neq 0$
\end{itemize}
erf\"ullt sind, dann gilt:
\[\exists g: I\ to K , I=(x_0-\epsilon,x_0+\epsilon), K=(y_0-\epsilon,y_0+\epsilon)\]
sodass: $y_0=g(x_0)$ mit $f(x,g(x))=0 \forall x\in I$
\end{emphbox}

\textbf{F\"ur implizite Funktionen mit mehrenen Gleichungen und mehreren Umbekannten:}\\
Man kann ein System aus $m$ Gleichungen mit $n$ Variablen und $m<n$ betrachten uns bis zu $m$ Variablen durch ausdr\"ucken mit den restlichen Variablen eliminieren!\\
VF: $F:\R^{k+m}\to\R^m, F(z)$ stetig differenzierbar mit Komponentenfunktionen $f_i:\R_{k+m}\to \R$\\
Gleichungssystem: $F(z)=0$ besitzt $m$ Gleichungen in $k+m$ Variablen.\\
Vektor $z\in\R^{k+m}$ wird ausgedr\"uckt durch Paar $z=(x , y)$ mit $x\in\R^k,y\in\R^m$.
Ziel: $G:\R^k\to\R^m, F(x,G(x))=0$ d.h. $y=G(x)$\\
EIne solche Funktion existier in der Umgebung um einen Punkt $z_0=(x_0,y_0)$ mit $F(z_0)=0$ falls die Teilmatrix $J_{F,y}(z_0)\in\R^{m \times m}$ der Jacobi-Matrix bestehend aus $\partial_j f_i(z_0), 1\le i \le m, k+1\le j \le k+m$ invertierbar ist!\\
\textbf{Beispiele:} Bei einer Gleichung l\"asst sich auch nur eine Variable eliminieren! Man kann oft aus verschiedenen Teilmatritzen(Teilweise $\R^{1\ times 1}$) w\"ahlen!\\
Aufl\"osen nach $x$: z.B: Es gibt eine Umgebung $B_\epsilon(y_0,z_0), K=(x_0-\delta,x_0+\delta)$ und ein vektorfeld $g:B_\epsilon \to K, x=g(y,z)$ mit $g(y_0,z_0)=x_0, f(g(y,z),y,z)=0 \forall (y,z) \in B_\epsilon$\\
Ableitungen: Kettenregel anwenden f\"ur z. B. $f(g(y,z),y,z)=0$ nach $y$ w\"ahre $0=\partial_x f(g(y,z),y,z)\cdot \partial_y g(y,z)+\partial_y f(g(y,z),y,z)\cdot 1 + \partial_z f(g(y,z),y,z) \cdot 0$. Allgemein: Leitet man nach $z$ ab, so Leitet man jeden Komponente nach $z$ ab, wobei man bei Kompositionen erst nach der Komponente ableiten muss um dann mit $z$ nachzudifferenzieren!\\
Ableitung aus Beispiel: $\partial_y g(y,z)=-\frac{\partial_y f(g(y,z),y,z)}{\partial_x f(g(y,z),y,z)}$\\
Hinweis: Sind die Ableitungen alle in expliziter Form, so l\"asst sich die Funktion wahrscheinlich auch in eine explizite Form bringen!\\
Bei mehreren Geichungen arbeitet man auch mit der Jacobimatrix und kann in $I:(x_0-\epsilon,x_0+\epsilon), V=B_r(y_0,z_0), g: I \to V$ aufl\"oosen mit z.B. $\vect{y \\ z}=g(x),y=g_1(x),z=g_2(x)$ und definiert zum Ableiten:\\
$F:\R^3\to\R^2$, $G:\R\to\R^3, G(x)=\vect{x \\ g_1(x), \\g_2(x)}$, $F(x,g_1(x),g_2(x))=F(G(x))$\\
Ableiten nach $x$ mit Kettenregel: $J_F(G(x))\cdot J_F(x)=\vect{0 \\ 0}$\\
$\Rightarrow \vect{g_1'(x)\\g_2'(x)}=J_{F,(y,z)}(G(x))^{-1} \cdot J_{F,x}(G(x))=J_G(x)$

\subsubsection{Satz der Umkehrabbildung}
$F:\Omega \subset \R^n \to \R^n$ umkehrbar $\Rightarrow F^{-1}(F(x))=x \forall x\ in \Omega$, $F,F^{-1}$ stetig differenzierbar $\Rightarrow J_{F^{-1}}(F(x))=J_F(x)^{-1}$ (falls Jacobi-Matrix invertierbar!), $J_{F^{-1}}(x)\cdot J_F(x)=\mathbbm{1}$\\
\textbf{Satz:} $\Omega \in \R^n, F: \Omega \to \R^n$ stetig differenzierbar, $x_0 \in \Omega, z_0=F(x_0)$, sei $J_F(x_0)$ invertierbar, dann gibt es eine Umgebung $U \subset \Omega$ von $x_0$ und eine Umgebung $V\subset F(\Omega)$ von $y_0$ sodass $F: U \to V$ bijektiv ist und eine Umkehrabbildung $F^{-1}: V \to U$ existiert. Es gilt: $F^{-1}$ ist stetig differenzierbar und $J_{F^{-1}}(x)=(J_F(x))^{-1}$ . Das bedeutet, dass die Funktion umkehrbar ist wenn die Jacobi-Matrix invertierbar ist!\\

\begin{sectionbox}
\begin{enumerate}
\item Suche Nullstelle von $f$: $(x_0,y_0)$ sodass $f(x_0,y_0)=0$
\item Ableiten nach der Variable, nach dem man Aufl\"osen will! $\partial_y f(x_0,y_0)\neq 0$ $\Leftrightarrow$ Satz anwendbar!
\item Satz liefert Existenz von $U$ und $g$ mit $g(x_0)=y_0$ und $f(x,g(x))=0 \forall x \in U_x$\\
Es existiert eine Umgebung sowohl in x-, als auch in y-Richtung, auf dem $g(x)$ definiertist. man kann nach $y$ aufl\"osen! Mann kann keine Angeben \"uber die Gr\"o\ss{}e der Umgebung machen, sie ist allerding offen und gr\"o\ss{}er als ein Punkt, kann aber winzig sein!\\
\item Die Ableitung von $h(x)=f(x,g(x))=0$ erh\"alt man durch Anwenden der Kettenregel!
\item Man kann $g$ so oft differenzieren, wie $f$ differenzierbar ist.
\item So kann man Aussagen \"uber $g(x_0),g'(x_0),...$ treffen
\item Bei Suche nach kritischen Punkten, Nenner ignorieren und z. B. Exponentialfunktionen $>0$ nutzen!
\item horizontale Tangente: $f_x=0$, vertikale Tangente: $f_y=0$
\item F\"ur Vektorfelder: z. B. $h(y)=\vect{x \\ z}$\\
$h(y_0)=\vect{x_0 \\ z_0}$\\
$f(h_1(y),y,h_2(y))=0 \forall y \in U$ Das bedeutet: $g_1(h_1(y),y,h_2(y))=0$ sowie $g_2(h_1(y),y,h_2(y))=0$, also $g_1-g_2=0$
\end{enumerate}
\end{sectionbox}

\begin{cookbox}{Aufl\"osbarkeit in Stelle $\vect{x_0 \\ y_0}$}
\item $f(x_0,y_0)=0$ aber $\nabla f(x_0,y_0)\neq 0 \Rightarrow$ lokal aufl\"osbar\\
\item bzw. $j_d(x_0,y_0)$ invertierbar!
\end{cookbox}

\begin{cookbox}{Umgebung und explizites $h(y)$}
\item  Nullstelle von $f$ in Abh\"angigkeit von $y$. (Meist durch Umstellen und Anwenden von Mitternachtsformel! W\"ahle entweder positive oder negative L\"osung je nachdem wie $(x_0,y_0)$ definiert sind, streiche restliche L\"osungen!)
\item Wann hat man reelle L\"osungen: erhalte Mengen
\item $(x_0,y_0)$ muss Teil der Umgebung sein
\item Berechnete Nulstelle: $h(y)$
\end{cookbox}

\begin{cookbox}{Ableitungen von $h(y)$}
\item  L\"ose $f$ nach $0$ auf
\item  Setze $x=h(y) \rightarrow f(h(y),y)$
\item Ableiten (ersetze $h(y_0) und y_0$ durch Zahlen) $\rightarrow$ Aufl\"osen nach $h'(y_0)$
\item Nochmal Ableiten (ersetze $y_0,h(y_0),h'(y_0)$) $\rightarrow$ Aufl\"osen nach $h''(y_0)$
\end{cookbox}
\subsection{Mittelwertsatz}
\textbf{Analysis 1:} $f:I\to\R$ stetig differenzierbar, $x,y \in I, x < y \exists $ eine Zwischenstelle $\xi \in (x,y)$mit $f(y)-f(x)=f'(\xi)(y-x)$ und folgender Absch\"atzung: $|f(y)-f(x)|\le C \cdot |y-x|$ mit Konstante $C=\max_{t \in [a,b]}f'(t)$\\
\textbf{Verallgemeinerung f\"ur Skalarfelder:}

\subsubsection{Mittelwertsatz f\'ur Skalarfelder}
$\Omega \subset \R^n$ offen, $f: \Omega \to \R$ ein stetig differenzierbares Skalarfeld und $x,y \in \Omega$. Zus\"atzlich muss die Verbindungstrecke$[x,y]\subset\Omega$ ganz in $\Omega$ enthalten sein. So gibt es Zwischenstelle $\xi \in [x,y]$ sodass: \[f(y)-f(x)=\nabla f(\xi)^\top (y-x)\] Absch\"atzung: \[|f(y)-f(x)|\le C \cdot \|x-y\|\] mit Konstante \[C=\max_{z\in[x,y]} \|\nabla f(z)\|\]
Beweis verwendet CSU und nutzt de Zur\"uckf\"uhrung der mehrdimensionalen Problem auf $\R$ um es mit dem Mittelwertsatz zu l\"osen.
Bedeutung: Wenn $\|\nabla f(x)\|$ gro\ss{} ist schwankt der Ausgangsgr\"o\ss{}e bei kleiner \"Anderung der Eingangsgr\"o\ss{}en sehr starb bzw. umgekrehrt. (Wie sensitiv reagiert ein System auf St\"oreinfl\"usse?)

\subsubsection{Matrixnormen}
\textbf{Spektralnorm:}\\
induzierte Matrixnorm!\\
\[\|A\|=\max_{v \in \R^n, v \neq 0} (\frac{\|A v \|}{\|v\|})\]\\
$\rightarrow A$ symmetrisch: gr\"o\ss{}ter Eigenwert!\\
$\rightarrow A$ nicht symmetrisch: gr\"o\ss{}ter Sigul\"arwert!\\
Submultiplikativit\"at gilt f\"ur alle induzierten Matrixnormen:
$\|A x\| \le \|A\| \cdot \|x\|$
euklidische 2-Norm?

\subsubsection{Mittelwertsatz f\"ur Vektorfelder}
$F: \Omega \subset \R^n \to \R^m$, $x,y \in \Omega$, $[x,y] \subset \Omega$\\
$F(x)=\mat{f_1(x) \\ \vdots \\ f_m(x)}$ mit Skalarfeldern $f_i: \Omega \to \R$\\
Nach dem MWS gibt es zwar Zwischenstellen $\Xi_1,...,\Xi_n \in (x,y)$ mit $f_i(y)-f_i(x)=\nabla f_i (\Xi_i)^\top (y-x)$ gilt, wobei diese im Allgemeinen NICHT gleich sind!\\
Problematisch ist hier der mehrdimensionale Bildraum! Mit dem Beispiel einer Kurve, welche den Viertelkreis beschreibt, kann man zeugen, dass die Differenz der Funktionswerte der Betrag des Vektors der Ableitungen nicht \"ubereinstimmen!\\
Dennoch gilt die Ungleichungsvariante des MWS auch f\"ur Vektorfelder:\\
$\Omega \ subset \R^n$ offen, $F:\Omega \to \R^m$ stetig differenzierbar, $x,y \in \Omega$, $[x,y] \subset \Omega$:\\
$\|F(y)-F(x)\|\le C \cdot \|y-x\|$, mit der Konstate $C = \max_{z \ in [x,y]} \|J_F (z)\|$ (Spektralnorm)!\\
\textbf{Integral-Version des Mittelwertsatzes f\"ur Vektorfelder:} $\Omega \subset \R^n$ offen, VF $f: \Omega \to \R^m$ stetig differenzierbar, $x,y \in \Omega, [x,y]\int \Omega$: \[f(y)-f(x)=\int_0^1 \! J_f(x+t(y-x))(y-x) \, \mathrm{d}t\] (Integral komponentenweise)
 
\section{Extremwertaufgaben/Optimierungsaufgaben}

\subsection{Extremwertaufgaben ohne Nebenbedingungen}
Man sucht h\"aufig Minima $\min_{x \in \Omega} f(x)$ und Maxima $\max_{x \in \Omega} f(x)$  einer skalaren Funktion $f: \Omega \subset \R^n \to \R$. Da man Vektoren schlecht vergleichen kann, macht eine Optimierung von vektorfeldern wenig Sinn!\\
\textbf{Tipp:} Bei gr\"o\ss{}eren Ausdr\"ucken abh\"angig von $x,y$ lohnt es sich oft Schritt f\"ur Schritt Auszuklammern mit Nutzung der Binomischen Formeln! Im Allgemeinen hier keinen Koordinatentransformationen verwenden! Bei Angabe von Vektoren, auch so viel Wie m\"oglich rausziehen, um Nullstellen einfacher zu sehen! Oft wird nach Globalem Minimum gesucht: Hierzu betrachtet man das Monotonieverhalten und z. B. gerade Potenzen,... Falls strikt global bitte Angeben!\\

\subsubsection{Extrema}
$\Omega \subset \R^n$, $f: \Omega \to \R$. Punkt $\hat{x} \in \Omega$ hei\ss{}t...\\\
\begin{itemize}
\item \textbf{globales Minimum} von $f$ auf $\Omega$ $\Leftrightarrow f(\hat{x})\le f(x) \forall x\ in \Omega$ 
\item \textbf{lokales Minumum} von $f$ auf $\Omega$  $\Leftrightarrow$ es gibt eine Umgebung $B_\epsilon(\hat{x})$: $f(\hat{x}) \le f(x) \forall x \in B_\epsilon(\hat{x}) \cap \Omega$
\item \textbf{striktes lokales Minimum} von $f$ auf $\Omega$  $\Leftrightarrow f(\hat{x}) < f(x) \forall x \in B_\epsilon \cap \Omega, x \neq \hat{x}$ 
\item \textbf{globales Maximum} von $f$ auf $\Omega$  $\Leftrightarrow f(\hat{x}) \ge f(x) \forall x \in \Omega$
\item \textbf{lokales Maximum} von $f$ auf $\Omega$  $\Leftrightarrow f(\hat{x}) \ge f(x) \forall x\in B_\epsilon \cap \Omega$ 
\item \textbf{striktes lokales Maximum} von $f$ auf $\Omega$  $\Leftrightarrow f(\hat{x}) > f(x) \forall x \in B_\epsilon \cap \Omega$
\end{itemize}

\subsection{Globale Extrema}
Wenn $\Omega$ offen ist(keinen Rand besitzt), (z.B. $\Omega=\R$) sind alle Minima/Maxima auch lokale Minima/Maxima! 
Trotzdem muss mit Grenzwerten pr\"ufen ob Die Funktionswerte nach oben oder unten unbeschr\"ankt sind! Hierzu reicht z. B. ein 1 Gegenbeispiel wie $\Lim{x\to \infty}f(x,0)=\infty,\Lim{x\to-\infty}f(x,0)=-\infty$

\subsubsection{Notwendige Optimatit\"atsbedingung erster Ordnung}
$f: \Omega \subset \R^n \to \R$ partiell differenzierbar, $\hat{x} \in \mathrm{int}(\Omega)$ (im Inneren) ein lokales Extrema. So gilt: $\nabla f(\hat{x})=0$\\
Nur Notwendig! GIt $\nabla f(\hat{x})=0$ so muss es sicht nicht zwingend um ein Extremum handeln! (siehe $x^3$)\\
Aussage gilt nur im Inneren von $\Omega$. Liegt $\hat{x}$ auf dem Rand $\hat{x} \in \partial \Omega$, so braucht $\nabla f(\hat{x})$ im Allgemeinen nicht gleich null zu sein!

\subsubsection{Aussagen \"uber die Hesse-Matrix}
Hesse matrix beinhaltet alle zweiten Ableitungen und ist meistens symmetrisch!\\
$f: \Omega \in \R^n \to \R$ zweimal stetig deifferenzierbar, also $f\in \mathcal{C}^2(\Omega)$ $\Leftrightarrow H_f$ symmetrisch $\Leftrightarrow H_f$ diagonalisierbar $\Leftrightarrow H_f$ besitzt reelle Eigenwerte $\lambda_1,...,\lambda_n$\\
\textbf{Definitheitseigenschaften:}\\
Matrix $A \in \R^{n \times n}$ symmetrisch hei\ss{}t...
\begin{itemize}
\item \textbf{positiv semidefinit} $\Leftrightarrow$ $x^\top A x \ge 0 \forall x \in \R^n \Leftrightarrow \lambda_i \ge 0 \forall 1 \le i \le n$
\item \textbf{positiv definit} $\Leftrightarrow$ $x^\top A x > 0 \forall x\in \R^n, x \neq 0\Leftrightarrow \lambda_i > 0 \forall 1 \le i \le n$
\item \textbf{negativ semidefinit}$\Leftrightarrow$ $x^\top A x \le 0 \forall x \in \R^n \Leftrightarrow \lambda_i \le 0 \forall 1 \le i \le n$
\item \textbf{negativ definit} $\Leftrightarrow$ $x^\top A x < 0 \forall x\in \R^n, x \neq 0\Leftrightarrow \lambda_i < 0 \forall 1 \le i \le n$
\item \textbf{indefinit} $\Leftrightarrow A$ ist weder positiv semidefinit, noch negativ semidefinit, also es gibt sowohl positive, als auch negative Eigenwerte!
\end{itemize}  
Ist $A \in \R^{n \times n}$ symmetrisch und positiv definit, so gilt: $x^\top A x \ge \lambda_1 \|x \|^2$, wobei $\lambda_1$ der kleinste Eigenwert von $A$ ist.\\
\textbf{Hurwitz-Kriterium:} Eine symmetrische bzw. hermitesche Matrix $A$ ist genau dann positiv definit, wenn alle führenden Hauptminoren(Hauptunterdeterminanten) von $A$ positiv sind. Da $A$ genau dann negativ definit ist, wenn $
-A$ positiv definit ist: $A$ ist genau dann negativ definit, wenn die Vorzeichen der führenden Hauptminoren alternieren, das heißt, falls alle ungeraden führenden Hauptminoren negativ und alle geraden positiv sind. Nicht anwendbar wenn Hauptunterdeterminanten gleich null sind!



\subsubsection{Optimatit\"atsbedingungen zweiter Ordnung}
Sei $\hat{x} \in (a,b)$ ein lokales Minimum im offenen Intervall mit $f'(\hat{x})=0$:\\
\textbf{Notwendige Bedingung:}  $f''(\hat{x}) \ge 0$\\
\textbf{hinreichend} $f''(\hat{x}) > 0 \Leftrightarrow \hat{x}$ ist ein lokales Minimum!\\
Beachte, dass zum Beispiel f\"ur $x^4$ $f''(0)=0$ obwohl es sich um ein Extremum handelt! (Nur hinreichend!)
Anderes Beispiel: $f(x)=3$!\\
\textbf{Notwendige Optimalit\"atsbedingung 2. Ordnung}\\
$f:\Omega \subset \R^n \to \R$ zweimal stetig differenzierbar, $\hat{x} \in \mathrm{int}\Omega$ ein lokales Minimum von $f$ $\Rightarrow$ $\nabla f(\hat{x})=0$ und Hessematrix $H_f$ positiv semidefinit!\\
Entsprechend f\"ur Maximum: $\nabla f(\hat{x})=0, H_f(\hat{x}) $negativ semidefinit\\
\textbf{Hinreichende Optimalit\"atsbedingung 2. Ordnung}\\
$f:\Omega \subset \R^n \to \R$ zweimal stetig differenzierbar, $\hat{x} \in \mathrm{int}\Omega,\nabla f(\hat{x})=0$ und Hessematrix $H_f$ positiv definit ($\rightarrow y^\top H_f y > 0 \forall y \in \R^n \diagdown \{0\}$)! $\Rightarrow \hat{x}$ ist ein lokales Minimum von $f$. \\

\begin{cookbox}{Bestimmung lokaler Extrema von $f$ im Inneren von $\Omega$}
\item Suche station\"are Punkte $\hat{x} \in \mathrm{int}\Omega: \nabla f(\hat{x})=0$
\item Bestimme Hesse-Matrix $H_f(\hat{x})$\\
\begin{itemize}
\item $H_f(\hat{x})$ positiv definit $\Rightarrow \hat{x}$ lokales Minimum
\item $H_f(\hat{x})$ negativ definit $\Rightarrow \hat{x}$ lokales Maximum
\item $H_f(\hat{x})$ indefinit $\Rightarrow \hat{x}$ weder lokales Minimum noch lokales Maximum $\rightarrow$ Sattelpunkt
\item $H_f(\hat{x})$ positiv(negativ) semidefinit aber alle EWe $\ge0$($\le 0$) und mindestens ein EW $=0$ $\Rightarrow \hat{x}$ keine Aussage m\"oglich! Man kann allerdings einen Sattelpunkt und lokale Maxima(Minima) ausschlie\ss{}en!\\
Manchmal kann man by inspection an den Funktionen sehen, ob Minima global, strikt,... sind.
\end{itemize}
\end{cookbox}

\subsection{Newton-Verfahren}
zur bestimmung von Nullstellen von $\nabla f$
\textbf{Taylor Polynom:} $f(x_0+d)\approx f(x_0) + \nabla f(x_0)^\top d + \frac{1}{2} d^\top H_f(x_0) d=g(d)$\\
Falls $H_f(x_0)$ invertierbar: $d=-H_f(x_0)^{-1} \cdot \nabla f(x_0)$\\
Dann $x_1=x_0+d \rightarrow d$ neu berechnen $x_2=x_1+d \rightarrow$ ...\\
Folge konvergiert gegen lokales Minimum! Abbrechen, wenn Genauigkeit passt! Newton-Verfahren klappt nicht immer!


\subsection{Lineare Ausgleichsrechung}
Gerade: $f(t)=x_0+x_1 t=b$ mit unbekannten Koeffizienten $x_0,y_0$\\
Aus Messungen bekommt man $m$ Paare $(t_i,b_i)$\\
Ziel: Bestimme $x_0,x_1$ f\"ur bestm\"ogliche N\"aherung!\\
$A x = b$ mit $x=\vect{x_0 \\ x_1}, b=\vect{b_0 \\ \vdots \\ b_m}$\\
$A=\mat{1 & t_1\\ 1 & t_2 \\ \vdots & \vdots \\ 1 & t_m}, (A | b)=\mat{1 & t_1 &  & b_0\\ 1 & t_2 &  & b_1 \\ \vdots & & & \vdots \\ 1 & t_m & & b_m}$\\
L\"osbar f\"ur $\mathrm{rang} \le 2$ (Alle Zeilen bis auf 2 linear Abh\"angig!)\\
Residuen: $r_i(x)=b_i-x_0-x_1 t$ sollen m|'oglichst klein werden!
Man kann nun $\|r(x)\|$, $\sum |r_i(x)|$, $\max |r_i(x)|$ minimieren, wobei die Methode mit $r=\vect{r_1 \\ \vdots \\ r_m}$ deutlich einfacher ist.
Allgemein gilt: $A x = b, A \in \R^{m \times n}, m>n$. L\"osung finden durch minimieren von $r=b-A x$\\
Normalengleichung: $A^\top A x=A^\top b$\\
Eine rechteckige Matrix $A \in \R^{m \times m}, m\ge n, \mathrm{Rang}( A)=n$ (Spalten linear unabh\"angig) $\Rightarrow$ $A^\top A$ positiv definit!\\
Folgerung: Im Rall $\mathrm{rang}(A)=n$ ist also $A^\top A$ invertierbar und die Normalengleichung l\"asst sich eindeutig l\"osen. Die L\"osung $\hat{x}$ ist ein globales Minimum!\\
L\"osung: TODO\\
Die Struktur der Ausgleichfunktion muss keine Gerade ein, kann sondern auch als Polynom, oder beliebige nichtlineare Funktion definiert werden! Gau\ss{}-Elimination ist nicht immer notwendig, manchmal einfach by inspection oder ineinander Einsetzen l\"osen und zweite gesuchte Variable ausrechnen!\\
Zus\"atzliche Bedigungen:\\
Vergehensweise bei Vorfaktoren usw: 
\begin{itemize}
\item $p(t_0)=f_0, p(t_4)=f_4, \sum_{i=1}^3(p(t_i)-f_i) \rightarrow \min$: $p(t)=c_0+c_1 t + c_2 t(t-4)+c_3 t^2 (t-4) \Rightarrow c_0,c_1$ bestimmen, Rest normal
\item $s=s(v)=a v^2 +b v, z=\frac{s}{v}, \sum_{i=1}^6 (z(v_i)-z_i)^2 \rightarrow min: z(v)=a v + b,$ Rest normal (Gewichtung ver\"andert das Ergebnis!)
\end{itemize}
\begin{itemize}
\item Start und Ende fest: Funktion so umschreiben, dass man durch einsetzen des Start und Endwertes die ersten 2 Unbekannten $c_0,c_1$ berechnen kann. Die restlichen Unbekannten l\"ost man mit der Normalengleichung.
\item Gewichtung: TODO
\end{itemize}

\subsection{Extremwertaufgaben unter Nebenbedinungen}
minimiere $f(x)$ unter der Nebenbedindung $g(x)=0$ mit $f,g:\Omega \subset \R^n \to \Omega$

\subsubsection{Zul\"assige Menge}
$\Omega_{ad}=\{x \in \Omega | g(x)=0\}$\\
$(P) \Leftrightarrow \min f(x), x\ in \Omega_{ad}$\\

\subsubsection{lokale L\"osung}
$\hat{x} \in \Omega$ hei\ss{}t lokale L\"osung von $(P)$ wenn es eine Umgebung $B_\epsilon(\hat{x})$ gibt, sodass $f(\hat{x})\le f(x) \forall x \in \B_\epsilon \cup \Omega_{ad}$, also $x\ in B_\epsilon(\hat{x}), g(x)=0$\\
Im allgemeinen gilt $\nabla f(\hat{x})=0 $NICHT!\\
L\"osungsweg einfach, wenn aufl\"osbar nach einer Variable. In andere Gleichung einsetzen und zweite Variable berechnen!\\
Allgemeines Schema: Ansatz \"uber Lagrange-Multiplikatoren\\
\subsubsection{Notwendige Optimalit\"atsbedigung 1. Ordnung}
$f,g$ Fr\'echet differenzierbar, $\hat{x} \in \mathrm{int} \Omega$ ein lokales Minimum der Aufgabe $\min f(x)$ mit $g(x)=0$. Falls $\nabla g(\hat{x}) \neq 0$, existiert ein Lagrange-Multiplikator $\hat{\lambda} \in \R$ mit $\nabla f(\hat{x}) + \hat{\lambda} \nabla g(\hat{x})$
Ist $\nabla g(\hat{x})=0$ und ist $\hat{x}$ ein lokales Minimum, so braucht $\nabla L(\hat{x},\hat{\lambda})$ nicht gleich null zu sein. Das hei\ss{}t man muss die Stellen, an denen $\nabla g(x)=0$ und $g(x)=0$ ist gesondert untersuchen!

\newcommand{\Lagr}{\mathcal{L}}

\subsubsection{Lagrange-Funktion}
$\Lagr: \Omega \times \R \to \R, \Lagr(x,\lambda)=f(x)+\lambda g(x)$\\
Ist $\hat{x} \in \mathrm{int} \Omega$ ein lokales Minimum von $f$ unter NB mit $\nabla g \neq = 0$, so gibt es ein $\hat{\lambda}$, sodass das Paar $(\hat{x},\hat{\lambda})$ ein station\"arer Punkt von $\Lagr$ ist. Also: $\nabla \Lagr (\hat{x},\hat{\lambda})=0$ mit $\nabla \Lagr(x,\lambda)=\vect{\partial_{x_1} \Lagr(x,\lambda) \\ \vdots \\ \partial_{x_n} \Lagr (x,\lambda)\\\partial_\lambda \Lagr(x,\lambda)}=\vect{\nabla_x \Lagr(x,\lambda) \\ \nabla_\lambda \Lagr(x,\lambda)}$\\
Hier: $\nabla \Lagr (x,\lambda)=\vec{\nabla f(x) + \lambda \nabla g(x) \\ g(x)}$

\subsubsection{Anmerkung}
Wie bei Extremwertaufgaben ohne Nebenbedigungen, gibt es hinreichende Optimalit\"atsbedigungen, auf auf den 2. Ableitungen der Lagrange Funktion basieren. Darauf wird nicht weiter eingegangen!\\

\begin{cookbox}{Extrema mit Nebenbedingungen}
\item $g$ nach $0$ aufl\"osen
\item $\exists$ lok. Extremum wenn $\nabla g \neq 0$ (Regularit\"atsbedingung)
\item Lagrange Funktion aufstellen $L(x,y,\lambda)=f+ \lambda g$
\item Berechne $\nabla L=0 \Rightarrow$ Extremstellen $P_i$
\item $P_i$ in $f$ einsetzen und vergleichen (Global?)
\item Tipps: Substituieren, Gradient nach x und y aufl\"osen, Manchmal mit Matrix-Gleichungssystem l\"osen!
\end{cookbox}

\subsubsection{Mehrere Nebenbedingungen}
SF $f: \Omega \subset \R^n \to \R,$ VF $g:\Omega \to \R^m$ ($m<n$)\\
Problem $(P): \min_{x\in \Omega}$ unter der Nebenbedingung $g(x)=\vect{g_1(x)\\\vdots\\g_m(x)}=0$\\
\textbf{Lagrange-Funktion:} $\Lagr:\Omega \times \R^m \to \R$, $\Lagr(x,\lambda)=f(x)+\lambda^\top g(x)=f(x)+\lambda_1 g_1(x)+...+\lambda_m g_m(x)$\\
\textbf{Notwendige Optimalit\"atsbedingung 1. Ordung:} $\hat{x}\in \mathrm{int}(\Omega) $ und $\mathrm{Rang}(J_g(\hat{x}))=m$ und $\hat{x}$ ist lokales Extremum von $(P) \Rightarrow \exists \hat{\lambda} \in \R^m: \nabla \Lagr(\hat{x},\hat{\lambda})=0 \Leftrightarrow \begin{cases} \nabla_x \Lagr (\hat{x},\hat{\lambda})=0 \\ \nabla_{\lambda_1} \Lagr(\hat{x},\hat{\lambda}) \\ \vdots \\ \nabla_{\lambda_m} \Lagr (\hat{x},\hat{\lambda})=0 \end{cases}=\begin{cases}  \nabla f(\hat{x})+\hat{\lambda}_1 g_1(\hat{x}) + ... + \hat{\lambda}_m g_m(\hat{x}) \\ g_1(\hat{x})=0 \\ \vdots \\ g_m(\hat{x})=0 \end{cases}$ \\
\textbf{WICHTIG:} Die Stellen $\hat{x}$ mit $\mathrm{Rang}(J_g(\hat{x}))<m$ (und $g(\hat{x})=0$) m\:ussen gesondert gepr\"uft werden! Das hei\ss{}t solche Stellen k\"onnen ein Extremum sein, ohne dass $\nabla \Lagr =0$ ist!

\section{Kurvenintegrale}
\subsection{Kurvenintegral eines Skalarfeldes}
$D \ subset \R^n $ offen, Kurve $w:I=[a,b]\to D$ differenzierbar, SF $f:D\to \R$ stetig.\\
Kurvenintegral von $f$ l\"angs $w$: $\int_x \! f \, \mathrm{d} s=\int_a^b\! f(w(t)) \cdot \|w'(t)\| \, \mathrm{d} t$\\
$\|w'(t)\|=\sqrt{sum_{i=1}^n(w_i'(t))^2}$.\\
L\"ange der Kurve mit $f=1$: $\L(w)=\int_w \! \mathrm{d} s=\int_a^b \! \|w'(t)\| \, \mathrm{d}t$\\
\textbf{Parametrisierung:}\\
Werden 2 Kurven $w:[a,b]\to \R^n, u:[c,d]\to \R^n$ mit der selben Spur (dem selben Bild), also $\{w(t)|a\le t \le b\}=\{u(t)|c\le t \le d\}$ genau gleich oft durchlaufen, dann gilt $\int_w \! f \, \mathrm{d} s=\int_u \! f \, \mathrm{d}s$\\
\textbf{Linearit\"at} f\"ur $\alpha,\beta\in\R$: \[\int_w \! (\alpha f + \beta g) \, \mathrm{d} s=\alpha \int_w \! f \, \mathrm{d} s + \beta \int_w \! g \, \mathrm{d} s\] 

\subsection{Kurvenintegral eines Vektorfeldes}
$D \subset \R^n$ offen, Kurve $w:[a,b]\to D$ differenzierbar, VF $f: D \to \R^n$ stetig.\\
Wegintegral von $f$ l\"angs $w$: $\int_w \! f \cdot \mathrm{d} x=\int_a^b \! f(w(t)) \cdot w'(t) \, \mathrm{d} t=\int_a^b \! f(w(t))^\top w'(t)\, \mathrm{d}t$\\
\textbf{Tangenteneinheitsvektor:} $T(t)=\frac{1}{\|w'(t)\|}w'(t) \Rightarrow \int_w \! f \, \mathrm{d} s=\int_w \! (f \cdot T) \, \mathrm{d}s \Rightarrow$ Kurvenintegral eines Vektorfeldes entlang der Kurve $w$ gleich dem Kurvenintegral der Tangentialkomponente $f \cdot T$ von $f$ entlang $w$.\\
\textbf{Linearit\"at} f\"ur $\alpha,\beta \in \R$: \\
\[\int_w \! (\alpha f + \beta g) \,\mathrm{d}x = \alpha \int_w \! f \, \mathrm{d}x + \beta \int_w \! g \, \mathrm{d} x\]
\textbf{Geschlossenes Kurvenitegral:} $w(a)=w(b) \Rightarrow \oint_w \! d \, \mathrm{d}x$

\subsection{Gradientenfelder}
\subsubsection{Wegzusammenh\"angigkeit}
$D \subset \R^n$ hei\ss{}t wegzusammenh\"angend, falls zu je 2 Punkten $x,y \in D$ eine Kurve $w:[a,b]\to D$ (ganz in $D$) existiert, sodass $w(a)=x,w(b)=y$

\subsubsection{Einfache Wegzusammenh\"angigkeit}
Eine wegzusammenh\"angende Menge $D \subset \R^n$ hei\ss{}t einfach wegzusammenh\"angend, wenn jede geschlossene Kurve stetig auf einen Punkt in $D$ zusammengezogen werden kann, ohne dass $D$ verlassen wird.\\
Kreisscheibe ist einfach zusammenh\"angend, Kreisscheibenring allerdings nicht! $\R^2 \diagdown \{0\}$ auch nicht! In $\R^2$ ist eine Menge ohne den Urspung nicht einfach wegzusammenh\"angend, in $\R^3$ allerdings schon!\\

\subsubsection{Gradientenfeld}
Offene wegzusammenh\"angende Menge $D \in \R^n$, stetiges VF $f: D\to\R^n$\\
$f$ konservativ/$F$ Potentialfeld/$f$ Gradientenfeld $\Leftrightarrow \exists $ SF $F:D\to\R$: $f(x)=\nabla F(x) \forall x \in D$\\
In deisem Fall hei\ss{}t $F$ Stammfunktion und manchmal ??? eine Potentialfunktion (ein Potential) von $f$.\\
Es gibt allerdings Vektorfelder, die keine Stammfunktion besizten und somit nicht konservativ sind! (Widerspruch erzeugen durch aufleiten!)\\
Ist  $f$ konservativ und kennt man die Stammfunktion: $ f=\nabla F \Rightarrow \int_w \! f \, \mathrm{d} x=F(w(t))-F(w(b))$\\ 
Wenn die Bedingung f\"ur den Satz nicht erf\"ullt sind, kann es sich trotzdem um ein Gradientenfeld handeln. Es reicht jedoch ein Gegenbeispiel um dies zu widerlelegen.

\subsubsection{Wegunabh\"angigkeit}
Bei einem Gradientenfeld h\"angt dasKurvenintegral nur vom Start- und Endpunkt ab. Man sagt, dass das Integral wegunabh\"angig ist.\\
Daraus folgt, dass das Wegintegral einer geschlossenen Kurve eines Gradientenfeldes gleich Null ist!

\subsubsection{\"Aquivalente Aussagen}
$D \subset \R^n$ wefzusammenh\"angend, offen, $f:D\to\R^n$:\\
\begin{enumerate}
\item $f$ ist Gradientenfeld
\item F\"ur alle stetig differenzierbaren Kurven in $D$ h\"angt $\int_w \! f \, \mathrm{d} x$ nur vom Anfang und Ende ab
\item F\"ur alle geschlossenen differenzierbaren Kurven gilt: $\oint_w \! w \, \mathrm{d}x=0$
\end{enumerate}

\subsubsection{Integrabilit\"atsbedingung}
offene EINFACH zusammenh\"angende Menge $D \subset \R^n$, VF $f:D\to \R^n$ stetig differenzierbar:\\
$f$ ist Gradientenfeld $\Leftrightarrow J_f(x)^\top=J_f(x)$ bzw. $\partial_{x_i}f_j(x)=\partial_{x_j}f_i \forall x \in D \forall1\le i,j \le n$\\
F\"ur:
\begin{itemize}
\item $D \subset \R^2$: $\partial_{x_1}f_2(x)=\partial_{x_2}f_1(x)$
\item $D \subset \R^3$: $\rot f(x)=0$
\end{itemize}

\subsubsection{Stammfunktion eines Gradientenfeldes}
Fester Punkt $x_0 \in D$, Kurve $w_y: [a,b]\to D$ zwischen $x_0$ und jedem Punkt $y\in D$, sodass $w_y(a)=x_0, w_y(b)=y$:
$F(y)=\int_{w_y}\! f \, \mathrm{d} x$\\
TODO
\paragraph{Aussagen zu Gradientenfeldern:}
\begin{itemize}
\item $f$ wegunabh\"angig
\item $\oint_w f d x=0$
\item $f \in \mathcal{C}^1 \rightarrow F \in \mathcal{C}^2$
\item $f(x)=\nabla F(x) \rightarrow J_f(x)=H_F(x)$
\end{itemize}

\begin{cookbox}{Bestimmtung der Stammfunktion eines Gradientenfeldes}
\item Pr\"ufe Bedingung f\"ur Existenz mit $\rot f=0$
\item $f(x,y,z)=\int v_1(x,y,z) d x \rightarrow + c(y,z)$
\item $\partial_y f(x,y,z)=v_2(x,y,z) \rightarrow + c(y,z)$ abh. von $c(z)$
\item $\partial_z f(x,y,z)=v_3(x,y,z) \rightarrow +c(z) $ oder $+c$
\end{cookbox}

\paragraph{Tipps:} Bei Parametrisierungen eines Teilst\"uckes aufpassen beim Umdrehen von Grenzen. Eventuell lieber $2 \pi - \phi$... $\cos(-x)^2+\sin(-x)^2=1$

\section{Mehrdimensionale Integralrechnung}
\subsection{Parameterabh\"angige Integrale}
SF $f:\R^2 \to \R, c,d \in \R$:\\
$F(x)=\int_c^d \! f(x,y) \mathrm{d} y$\\
\textbf{Stetigkeit \"ubertragbar?}\\
Stetigkeit von $F$ an der Stelle $x = 0 \Leftrightarrow \int_c^d \! \Lim{x \to 0} f(x,y) d y$\\
Vertauschbarkeit zweier Grenzprozesse ist immer nur unter gewissen Vorraussetzungen m\"oglich\\

\subsubsection{Stetigkeit}
$I=[a,b], J=[c,d], f: i \times J \to \R$ stetig auf $I \times J, F: I \to \R$\\
$F(x)=\int_c^d \! f(x,y) d y$ stetig auf $I$\\
Fordert Stetigkeit als Skalarfeld!\\
Verallgemeinerung auf uneigentliche Integrale m\"oglich!

\subsubsection{Differenzierbarkeit}
$I=[a,b],J=[c,d], f: I \times J \to \R, \partial_x f$ stetig auf $I \times J$\\
$F: I \to \R$ mit $F(x)=\int_c^d \! f(x,y) d y$ stetig differenzierbar auf $I$ mit $F'(x)=\int_c^d \! \partial_x f(x,y) d y$\\
Verallgemeinerung auf uneigentliche Integrale m\"oglich!

\subsubsection{Formel von Leibniz}
$F(x)=\int_{c(x)}^{d(x)} \! f(x,y) d y$\\
SF $G: \R^3 \to \R, G(x,a,b)=\int_a^b \! f(x,y) d y$\\
Es gilt: $F(x)=G(x,c(x),d(x))$\\
$\Rightarrow F'(x)=\int_{c(x)}^{d(x)} \! \partial_x f(x,y) d y + f(x,d(x)) d'(x) - f(x,c(x))c'(x)$

\subsubsection{Satz von Fubini}
$I=[a,b],J=[c,d], f:I \times J \to \R$ stetig auf $I \times J$:
\[\int_a^b (\int_c^d f(x,y) d y)d x=\int_c^d (\int_a^b f(x,y) d x)d y\]
Spezialfall: $f(x,y)=g(x)h(y)$
\[\int_a^b(\int_c^d g(x)h(y) d y) d x=(\int_a^b g(x) d x)(\int_c^d h(y) d y)\]\\
Verallgemeinerung auf mehr als zwei Integrale ergibt f\"ur $\R^3 \to \R$ 6 M\"oglichkeiten!

\subsection{Bereichsintegrale}
\subsubsection{Integration \"uber Rechtecke und Quader}
achsenparalleles Rechteck $Q = [a, b] \times [c, d] \subset \R^2$, SF $f: Q \to \R$\\
Doppelintegral von $f$ \"uber $Q$ $V=\int \int_Q f(x,y) d(x,y)$ soll dem Volumen unter dem Graphen von $f$ entsprechen!\\
Integral f\"ur Treppenfunktion $g$ bzgl $(Z_1,Z_2)$: \[\int \int_Q g(x,y)d(x,y)=\sum_{i=1}^n \sum_{j=1}^m c_{ij} (x_i-x_{i-1})(y_j-y_{j-1}) \]
Unter- und
eine Obersumme bzgl. $(Z_1,Z_2)$ f\"ur $f$: \[U_{Z_1,Z_2} (f)=\sum_{i=1}^n \sum_{j=1}^m m_{ij}(x_i-x_{i-1})(y_j-y_{j-1})\] \[O_{Z_1,Z_2} (f)=\sum_{i=1}^n \sum_{j=1}^m M_{ij}(x_i-x_{i-1})(y_j-y_{j-1})\]
mit $m_{ij}=\inf_{x\in (x_i-x_{i-1}),y \in (y_j-y_{j-1})} f(x,y), M_{ij}=\sup_{x\in (x_i-x_{i-1}),y \in (y_j-y_{j-1})} f(x,y)$\\
Ober- und Unterintegral: $U(f)=\sup \{U_{Z_1,Z_2}(f)|(Z_1,Z_2) $ Zerlegungen von $Q \}$\\
Ober- und Unterintegral: $O(f)=\inf \{O_{Z_1,Z_2}(f)|(Z_1,Z_2) $ Zerlegungen von $Q \}$\\
Falls $U(f)=O(f)$ ist das Riemann-Integral: $\int \int_Q f(x,y)d(x,y)=U(f)=O(f)$\\
Schreibweisen: $\int_Q f(x,y)d(x,y)=\int \int_Q f(x,y)d F$ mit Fl\"achenelement $d F=d(x,y)=d x d y$\\
Satz von Fubini f\"ur Bereichsintegrale: Rechteck $Q=[a,b] \times [c,d] \subset \R^2$, stetiges SF $f: Q \to \R \Rightarrow f$ integrierbar \"uber $Q$ mit: \[\int \int_Q f(x,y)d(x,y)=\int_a^b (\int_c^d f(x,y) d y)d x=\int_c^d (\int_a^b f(x,y) d x)d y\]\\
Wichtig: Pr\"ufe erst Vorraussetzung, dass der Integrand stetig sein muss, erst dann Schritt von $\int \int_\Omega f d(x,y) \to \int_a^b \int_c^d f d y d x$ m\"oglich! (Anmerken!) \\ 
Wieder ist Verallgemeinerung f\"ur h\"ohere Dimensionen m\"oglich und f\"ur $g(x,y,z)=g_1(x)g_2(y)g_3(z)$ eine Vereinfachung m\"oglich!
\subsubsection{Integrale \"uber allgemeine Bereiche}
allgemeiner Bereich: $\Omega \subset \R^2, \Omega \subset \R^3,...$\\
\textbf{Charakteristische Funktion:} Menge $\Omega \subset \R^n, \chi_\Omega: \R^n \to \R, \chi_\Omega(x)=\begin{cases} 1, x \in \Omega \\ 0, $sonst$ \end{cases}$\\
\textbf{Fl\"achenbegriff:} Eine beschr\"ankte Menge kann man immer in ein Rechteck einbetten, $\Omega \subset Q$\\
$\Omega \subset \R^2 $ Jordan messbar $\Leftrightarrow$ $\Omega \subset Q$ und $\chi_\Omega$ \"uber Q integrierbar. Fl\"ache:
\[\int \int_Q \chi_\Omega (x,y) d(x,y)\]
$\Omega \subset \R^2$ sei Jordan messbar und $Q$ ein Rechteck mit $\Omega \subset Q$, SF $f: \Omega \to \R$ ist integrierbar \"uber $\Omega$, falls $f \chi_\Omega$ \"uber $Q$ integrierbar ist. Integral: 
\[\int \int_Q f(x,y)d(x,y)=\int \int_Q f(x,y)\chi\Omega(x,y)d(x,y)\]
Fl\"che von$ \Omega$: $F(\Omega)=\int \int_Omega 1 d(x,y)$\\
F\"ur $F(\Omega)=0$ ist $\Omega$ eine Nulstellenmenge (Eine endliche Menge von Punkten in $\R^2$ oder das Bild einer regul\"aren Kurve in $\R^2$)\\
Volumen von $\Omega \subset \R^3$: \[V(\Omega)=\int \int \int_Q \chi_\Omega (x,y,z)d(x,y,z)\]
Integral: \[\int \int \int_\Omega f(x,y,z)d(x,y,z)=\int \int \int_Q f(x,y,z) \chi_\Omega(x,y)d(x,y,z)\]
Volumen $V(\Omega)=\int \int \int_\Omega 1 d(x,y,z)$

\begin{cookbox}{Rechenregeln f\"ur Bereichtsintegrale}
\item $\Omega \in \R^2$ Jordan messbar, $f,g : \Omega \to \R$ int'bar \"uber $\Omega$, $\alpha,\beta \in \R$:\\
$\int \int_\Omega \! (\alpha f + \beta g) d(x,y)=\alpha \int \int_\Omega f d(x,y) + \beta \int \int_\Omega g(x,y) d(x,y)$
\item Nullmenge $N \subset \R^2$, SF $f$ beschr\"ankt: $\int \int_N f(x,y) d(x,y)=0$
\item $\Omega_1,\Omega_2$ Jordan messbar, $ \Omega_1 \cup \Omega_2=\emptyset, \Omega_1 \cap $ eine Nullmenge. F\"ur alle \"uber $\Omega=\Omega_1 \cup \Omega_2$ int'baren SF: $\int \int_\Omega f(x,y) d(x,y) =\int \int_{\Omega_1} f(x,y) d(x,y) + \int \int_{\Omega_2} f(x,y) d(x,y)$
\item $\Omega \subset \R^2$ Jordan messbar, SF $f:\Omega \to \R$ int'bar \"uber $\Omega$, Nullmenge $N \subset \Omega$: \"andert man f auf der Menge $N$ ab, so bleibt das Integral unver\"andert
\item Regaln analog f\"ur Dreifachintegrale!
\end{cookbox}
\subsubsection{Normalbereiche}
Man kann \"uber dieser Klassen von Mengen fast so einfach integrieren, wie \"uber Rechtecke und Quader!
\paragraph{Typ 1}
$I=[a,b] ; c,d: i \to \R$ stetig $c(x) \le d(x) \forall x \in I$:\\
$\Omega=\{(x,y) \in \R^2 | a \le x \le b, c(x) \le y \le d(x)\}$\\
$\int \int_\Omega f(x,y) d(x,y)=\int_a^b (\int_{c(x)}^{d(x)} f(x,y) d y)d x$ (Feste Intervallgrenzen aussen!)
\paragraph{Typ 2}
$I=[c,d] ; a,b: i \to \R$ stetig $a(y) \le b(y) \forall y \in I$:\\
$\Omega=\{(x,y) \in \R^2 | c \le y \le d, a(y) \le x \le b(y)\}$\\
$\int \int_\Omega f(x,y) d(x,y)=\int_c^d (\int_{a(y)}^{b(y)} f(x,y) d x)d y$ (Feste Intervallgrenzen aussen!)
\paragraph{Vorgehensweise}
Ist $\Omega$ kein Normalbereich, versucht man die Menge in endlich viele disjunkte Normalbereiche zu zerlegen und diese aufzuaddieren!
\paragraph{Normalbereiche in $\R^3$}
6 M\"oglichkeiten wie z. B. $\Omega=\{(x,y,z) \in \R^3 | c \le y \le d, a(y) \le x \le b(y), e(x,y) \le z \le f(x,y)\}$
\begin{itemize}
\item erste Variable: feste Intervallgrenzen
\item zweite Variable: abh\"anging von 1. Variable
\item dritte Variable: abh\"angig von 1. und 2. Variable
\end{itemize}

\paragraph{Volumen von K\"orpern}
Man sollte immer Symmetrieeigenschaften nutzen um nur einfachere Bereiche betrachten zu m\"ussen, am Ende aber nicht vergessen das gesamte Volumen anzugen! Dritte variablen muss nicht von beiden voherigen Variablen abh\"angen! Bei Koordinatentransformation die Determinante sowie die Norm nicht vergessen!\\
Skizzen! K\"orper benennen: z. B. Kugel mit Angabe von Radius und Mittelpunkt, bei Halbkugel Orientierung,...

\subsubsection{Transformation des Bereichsintegrals}
\textbf{1D:} $\int_a^b f(\phi(t))\phi'(t)d t=\int_{\phi(a)}^{\phi(b)} f(x) dx$\\
\textbf{Transformationssatz:} $\Omega \subset \R^n$ offen, Transformation $\Phi: \Omega \to \R^n$ regul\"ar und differenzierbar\\
\[\int_{\Phi(\Omega)} f(x) d x=\int_{\Omega} f(\Phi(u))|\det J_{\Phi}(u) d u\] mit $\Phi(\Omega)$: Bild der Menge $\Omega$ unter der Transformation $\Phi$, $J_\Phi(u)$: Jecobi-Matrix, $\det J_\Phi(u)$: Funktionaldeterminante. Transformation regul\"ar, wenn $\det J_\Phi(u)\neq 0$\\
Oft kann man komplizierte Bereiche durch Transformation auf Normalbereiche zur\"uckf\"uhren!

\subsection{Fl\"achenintegrale}
\subsubsection{Fl\"ache}
$B \subset \R^2$ messbar\\
Vektorfeld $\phi:B \to \R^3$ (st\"uckweise differenzierbar ) hei\ss{}t Fl\"ache\\
$\phi(u,v)=\vect{x(u,v)\\y(u,v)\\z(u,v)}$\\
\begin{itemize}
\item Graph eines SF als Fl\"ache: $\phi(u,v)=\vect{u\\v\\f(u,v)}$
\item Mantelfk\"ache Zylinder: $\phi(u,v)=\vect{R \cos u \\ R \sin u \\ v}$
\item Kugeloberfl\"ache: $\phi(u,v)=\vect{R \cos u \sin v\\R \sin u \sin v \\ R \cos u}$
\item Rotationsfl\"ache eines Kurvenst\"ucks: ?
\end{itemize}
\paragraph{regul\"arer Punkt}
Ein Punkt $\phi(u_0,v_0)$ hei\ss{}t regul\"ar, falls die Tangentialvektoren $\partial_u \phi(u_0,v_0)$ und $\partial_v \phi(u_0,v_0)$ linear unabh. sind, also $\partial_u \phi(u_0,v_0)\times \partial_v \phi(u_0,v_0)=0$

\paragraph{Kreuzprodukt:}
DEF!?\\
$a,b \in \R^n, a \times b RECHTWINKLIG a, a \times b RECHTWINKLIG b, \|a \times b \|=\|a\|\|b\| \sin \phi, \phi = \deg(a,b), a \times b = 0 \Leftrightarrow $ a,b lin. abh.\\
Fl\"acheninhalten eines von $a$,$b$ aufgespannten Parallelogrammes: $F(P)=\|a \times b|$

\paragraph{regul\"are Fl\"ache}
Alle Punkte der Fl\"ache sind regul\"are Punkte. Es l\"asst sich ein Normalenvektor bzw. ein Einheitsnormalenvektor zur Fl\"ache definieren mit: $n(u_0,v_0)=\frac{1}{\|\  \partial_u \phi(u_0,v_0) \times \partial_v \phi(u_0,v_0)  |}\partial_u \phi(u_0,v_0) \times \partial_v \phi(u_0,v_0)$

\paragraph{Fl\"acheninhalt:}
nach Grenz\"ubergang:\\
\[F(\phi)=\int \int_B \| \partial_u \Phi(u,v) \times \partial_v \Phi(u,v)\| d(u,v)\] falls Integral existiert!	


\subsubsection{Oberfl\"achenintegral}
\paragraph{Skalarfeld}
SF $f: \R^3 \to \R$ beschr\"ankt, Fl\"ache $\phi: B \subset \R^2 \to \R^3$:\\
Oberfl\"achenintegral von $f$ \"uber $\phi$:
\[\int \int_\phi f d O = \int \int_B f(\phi(u,v)) \|\partial_u \phi(u,v) \times \partial_v \phi(u,v)\|\] falls existent mit dem Oberfl\"achenelement $d O=\|\partial_u \phi(u,v) \times \partial_v \phi(u,v)\|$\\

\paragraph{Vektorfeld}
VF $F:\R^3 \to \R^3$ beschr\"ankt, Fl\"ache $\phi: B \subset \R^2 \to \R^3$:\\
Oberfl\"achenintegral von $F$ \"uber $\phi$:
\[\int \int_\phi F d O=\int \int_B F(\phi(u,v))^\top (\partial_u \phi(u,v) \times \partial_v \phi(u,v))d(u,v)\] (falls existent! Fluss von $F$ durch $\phi$)
(Kurve: $\int_k F d x = \int_k (F \cdot T)$ mit Einheitstangentialvektor $T$ und Tangentialkomponente $(F \cdot T)$ von $F$)\\
Vektorfeld: $\int \int_\phi F d 0=\int \int_\phi (F \cdot n) d O$ mit Normaleneinheitsvektor $n$ und Normalkomponente $(F \cdot n)$ von $F$.

\subsection{Integrals\"atze}
\subsubsection{positiver Umlauf}
$\Omega \subset \R^2$ messbar, geschlossene, st\"cukweise regul\"are Kurve beschreibt Rand $\partial \Omega$. W\"alt man die Parametrisierung so, dass $\Omega$ immer links zur Durchlaufrichtung ist spricht von von einem positivem Umlauf
\subsubsection{Satz von Green} (zweidimensional)
$\Omega \subset \R^2$ mit $\partial \Omega$ durch positiven Umlauf parametrisiert, VF $v: \overline{\Omega} \to \R^2$ stetig differenzierbar:
\[\int \int_\Omega \partial_x v_2 - \partial_y v_1 d ??=\int \int_{\partial \Omega} v d x\]
Mit Abschluss $\overline{\Omega}=\Omega \cup \partial \Omega$\\
Nutzen: Bestimme ein Fl\"achenintegral einer Menge $\Omega$ durch ein Kurvenintegral \"uber einem Vektorfeld mit $\partial_x v_2 - \partial_y v_1=1$. W\"ahle z. B. $v(x,y)=\frac{1}{2} \vect{-y \\ x}$

\subsubsection{Satz von Gau\ss{}} (zweidimensional)
Menge $\Omega \subset \R^2$ mit $\partial \Omega$ parametrisiert durch st\"uckweise regul\"are, geschlossene Kurve $\gamma=\gamma(t)$, VF $v:\overline{\Omega} \to \R^2$ stetig differenzierbar:\\
\[\int \int_\Omega \div v d(x,y)=\int_{\partial \Omega} v^\top n d s\] wobei $n=n(t)$ den Einheitsnormalenvektor zu $\gamma(t)$ beschreibt, welcher nach aussen zeigt!
\subsubsection{Satz vvon Gau\ss{}} (dreidimensional)
Menge $\Omega \subset \R^3$, Rand $\partial \Omega$ beschrieben durch st|"uckweise regul\"are, geschlossene Fl\"ache, VF $ v:\overline{\Omega}\to \R^3$ stetig differenzierbar:
\[\ iiint_\Omega \div v d(x,y,z)=\iint_{\partial \Omega} v^\top n d O=\iint_{\partial \Omega} v d O\] mit Einheitsnormalenvektor $n$ zur Oberfl\"ache nach au\ss{}en\\
Gesamtfluss einen Vektorfeldes ist gegeben durch das Bereichintegral \"uber den Rand. Ist die Divergrenz gleich 0, verschwindet der Gesamtfluss (divergenzfreies VF), man spricht zum Beispiel von Inkombressibilit\"at bei Fl\"ussigkeiten!\\
Mit Laplace: $\iiint_\Omega \Delta u d(x,y,z)=\iiint_\Omega \div(\nabla u) d(x,y,z)=\iint_{\partial \Omega} \nabla u^\top n d O$ (Normalenfluss des Gradienten)

\subsubsection{Greensche Formel}
$\Omega \subset \R^3, \partial \Omega$ wie im Satz von Gau\ss{}, SF $\phi: \overline{\Omega} \to R$ stetig differenzierbar, SF $u: \overline{\Omega} \to \R$ zweimal stetig differenzierbar:\\
\[\iint_\Omega \Delta u \phi d(x,y,z)=-\iiint(\Delta u \nabla \phi d(x,y,z) + \iint_{\partial \Omega} \phi \nabla u^\top n d O)\]
Verallgemeinerung der partiellen Integration!

\subsubsection{Einseitige und zweiseitige Fl\"achen}
Bei einer zweiseitigen Fl\"ache in $\R^3$ ist die Oberseite der Fl\"ache durch den Einheitsnormalenvektor eindeutig definiert.
\textbf{Beispiele:} M\"obius-Band(einseitig, NICHT zweiseitig), TODO?

\subsubsection{Orientierung}
Fl\"ache $\phi$ zweiseitig und regul\"ar mit \"uberschneidungsfreier Randkurve $\partial \phi$. $\phi$ ist positiv orientiert, falls die Kurve so parametrisiert ist, dass die Oberseite der Fl\"ache immer links der Kurve linkt und ansonsten negativ orientiert.

\subsubsection{Satz von Stokes} (Verallgemeinerung des Satz von Green)
Fl\"ache $\phi: B \subset \R^2 \to \R^3$ zweiseitig, st\"uckweise regul\"ar, Randkurve $\partial \phi$ positiv orientiert, Menge $D$ offen, $\phi(B) \subset D, $VF $c: D \to \R^3$ stetig differenzierbar:
\[\iint_\phi \rot v d O=\int_{\partial \phi} v d t\]
\textbf{Beispiele:} Die Randkurve einer Halbsphare ist ein Kreis, so kann man sich die umst\"andliche Berechnung des Integrals der Rotation ersparen, indem man ein Kurvenintegral ausrechnet.




% DOCUMENT_END =================================================================
\end{document}